<!DOCTYPE html>
<html>
<head>
  <!-- hexo-inject:begin --><!-- hexo-inject:end --><meta charset="utf-8">
  <meta http-equiv="X-UA-Compatible" content="IE=edge" />
  
  <title>用Gibbs采样训练LDA模型 | 张慕晖的博客</title>
  
  

  
  <link rel="alternate" href="/atom.xml" title="张慕晖的博客">
  

  <meta name="HandheldFriendly" content="True" />
  <meta name="apple-mobile-web-app-capable" content="yes">
  <meta name="viewport" content="width=device-width, initial-scale=1, maximum-scale=1">
  <!-- meta -->
  

  <!-- link -->
  <link rel="stylesheet" href="https://cdn.jsdelivr.net/gh/fancyapps/fancybox@3.5.7/dist/jquery.fancybox.min.css" />
  
  <link rel="stylesheet" href="https://cdn.jsdelivr.net/npm/node-waves@0.7.6/dist/waves.min.css">
  
  <link rel="stylesheet" href="https://cdn.jsdelivr.net/npm/@fortawesome/fontawesome-free@5.6.3/css/all.min.css">
  
  
  <link rel='stylesheet' href='https://cdnjs.cloudflare.com/ajax/libs/KaTeX/0.10.0/katex.min.css'>
  

  
  <link rel="shortcut icon" type='image/x-icon' href="/files/favicon.ico">
  

  
  <link rel="stylesheet" href="/style.css">
  

  <script>
    function setLoadingBarProgress(num) {
      document.getElementById('loading-bar').style.width=num+"%";
    }
  </script>

  
    <!-- Global site tag (gtag.js) - Google Analytics -->
    <script async src="https://www.googletagmanager.com/gtag/js?id=UA-119345306-1"></script>
    <script>
      window.dataLayer = window.dataLayer || [];
      function gtag(){dataLayer.push(arguments);}
      gtag('js', new Date());
      gtag('config', 'UA-119345306-1');
    </script><!-- hexo-inject:begin --><!-- hexo-inject:end -->
  
  
</head>

<body>
    <!-- hexo-inject:begin --><!-- hexo-inject:end --><div id="loading-bar-wrapper">
  <div id="loading-bar" class="pure"></div>
</div>

    <script>setLoadingBarProgress(20)</script>
    <header class="l_header pure">
	<div class='wrapper'>
		<div class="nav-main container container--flex">
      <a class="logo flat-box" href='/' >
        
          张慕晖的博客
        
      </a>
			<div class='menu'>
				<ul class='h-list'>
          
				</ul>
			</div>

			
				<div class="m_search">
					<form name="searchform" class="form u-search-form">
						<input type="text" class="input u-search-input" placeholder="搜索" />
						<span class="icon"><i class="fas fa-search fa-fw"></i></span>
					</form>
				</div>
			
			<ul class='switcher h-list'>
				
					<li class='s-search'><a class="fas fa-search fa-fw" href='javascript:void(0)'></a></li>
				
				<li class='s-menu'><a class="fas fa-bars fa-fw" href='javascript:void(0)'></a></li>
			</ul>
		</div>

		<div class='nav-sub container container--flex'>
			<a class="logo flat-box"></a>
			<ul class='switcher h-list'>
				<li class='s-comment'><a class="flat-btn fas fa-comments fa-fw" href='javascript:void(0)'></a></li>
				<li class='s-toc'><a class="flat-btn fas fa-list fa-fw" href='javascript:void(0)'></a></li>
			</ul>
		</div>
	</div>
</header>
	<aside class="menu-phone">
    <header>
		<nav class="menu">
      <ul>
          
      </ul>
		</nav>
    </header>
	</aside>

    <script>setLoadingBarProgress(40);</script>
    <div class="l_body">
    <div class='container clearfix'>
        <div class='l_main'>
            <article id="post" class="post white-box article-type-post" itemscope itemprop="blogPost">
  
<section class='meta'>
  
  
  <div class="meta" id="header-meta">
    
      
          <h1 class="title">用Gibbs采样训练LDA模型</h1>
      
    

    <div class='new-meta-box'>
      
        <div class='new-meta-item author'>
          <a href="https://zhanghuimeng.github.io">
            <i class="fas fa-user" aria-hidden="true"></i>
            张慕晖
          </a>
        </div>
      
      
        <div class="new-meta-item date">
          <a class='notlink'>
            <i class="fas fa-calendar-alt" aria-hidden="true"></i>
            2020-03-18
          </a>
        </div>
      
      
        
      
      
        
          <div class="new-meta-item browse busuanzi">
            <a class='notlink'>
              <i class="fas fa-eye" aria-hidden="true"></i>
              <span id="busuanzi_value_page_pv">
                <i class="fas fa-spinner fa-spin fa-fw" aria-hidden="true"></i>
              </span>
            </a>
          </div>
        
      
      
    </div>
    <hr>
  </div>
</section>

    <section class="article typo">
      <div class="article-entry" itemprop="articleBody">
        <p>本文将详细讲解LDA模型的推导过程，并附有示例代码。</p>
<a id="more"></a>
<p>LDA是一种文档主题模型，它生成文档的过程是这样的：</p>
<ul>
<li>从Dirichlet分布$\alpha$中采样，生成文档$i$的主题分布$\theta_i$</li>
<li>从多项式分布$\theta_i$中采样，生成文档$i$的第$j$个词的主题$z_{i,j}$</li>
<li>从Dirichlet分布$\beta$中采样，生成主题$z_{i,j}$对应的词语分布$\phi_{z_{i,j}}$</li>
<li>从多项式分布$\phi_{z_{i,j}}$中采样，最终生成词$w_{i,j}$</li>
</ul>
<h2>数学基础</h2>
<h3>二项分布</h3>
<p>抛一硬币$n$次，硬币正面朝上的概率为$p$，反面朝上的概率为$1-p$，则骰子正面朝上$k$次的概率为</p>
<p>$$<br>
P(X=k) = \binom{n}{k} p^k (1-p)^{n-k}<br>
$$</p>
<p>记作二项分布$X \sim B(n, p)$。</p>
<h3>二项分布的共轭先验分布：Beta分布</h3>
<p>贝叶斯公式为</p>
<p>$$<br>
P(\theta|X) = \frac{P(X|\theta)P(\theta)}{P(X)} \propto P(X|\theta)P(\theta)<br>
$$</p>
<p>其中$P(X|\theta)$称为似然函数，$P(\theta)$称为先验分布，$P(\theta|X)$称为后验分布。如果先验分布和似然函数可以使得先验分布和后验分布的形式相同，则称先验分布和似然函数是共轭分布，$P(\theta)$是$P(\theta|X)$的共轭先验。</p>
<p>Beta分布有两个参数$\alpha&gt;0$和$\beta&gt;0$，其概率密度函数为</p>
<p>$$f(x ; \alpha, \beta)=\frac{1}{B(\alpha, \beta)} x^{\alpha-1}(1-x)^{\beta-1}$$</p>
<p>记为$X \sim Beta(\alpha, \beta)$，其中</p>
<p>$$B(\alpha, \beta)=\frac{\Gamma(\alpha) \Gamma(\beta)}{\Gamma(\alpha+\beta)}$$</p>
<p>将二项分布作为似然函数，得到</p>
<p>$$P(X | \theta) \propto \theta^{k}(1-\theta)^{n-k}$$</p>
<p>Beta分布作为先验分布，得到</p>
<p>$$<br>
P(\theta) \propto \theta^{\alpha - 1}(1 - \theta)^{\beta - 1}<br>
$$</p>
<p>于是有</p>

$$
\begin{aligned}
P(\theta | X) & \propto P(X|\theta)P(\theta) \\
& \propto \theta^{k}(1-\theta)^{n-k} \theta^{\alpha - 1}(1 - \theta)^{\beta - 1} \\
& = \theta^{\alpha+k-1} (1 - \theta)^{\beta+n-k-1}
\end{aligned}
$$

<p>可以发现，后验分布服从$Beta(\alpha+k, \beta+n-k)$，因此Beta分布是二项分布的共轭先验分布。</p>
<h3>多项分布</h3>
<p>多项分布是二项分布的推广形式。令$x_1+x_2+ \cdots x_k = n$，$p_1 + p_2 + \cdots + p_k = 1$，则多项分布的概率为</p>
<p>$$<br>
f(x_1, x_2, \cdots x_k | n, p_1, p_2, \cdots, p_k) = \frac{n!}{x_1!\cdots x_k!} p_1^{n_1} \cdots p_k^{n_k}<br>
$$</p>
<p>记为$X \sim Mult(n, p_1, \cdots, p_n)$。</p>
<h3>多项分布的共轭先验分布：Dirichlet分布</h3>
<p>Dirichlet分布的概率密度函数为</p>
<p>$$<br>
f(p_1, p_2, \cdots, p_k | \alpha_1, \alpha_2, \cdots \alpha_k) = \frac{1}{\Delta(\alpha_1, \cdots, \alpha_k)} p_1^{\alpha_1-1}\cdots p_k^{\alpha_k-1}<br>
$$</p>
<p>其中</p>
<p>$$\Delta(\alpha_1, \cdots, \alpha_k)=\frac{\Gamma(\alpha_1)\cdots\Gamma(\alpha_k)}{\Gamma(\alpha_1+\cdots+\alpha_k)}$$</p>
<p>记为$P \sim Dir(\alpha_1, \cdots, \alpha_k)$。它的期望为$E(p_i)  = \frac{\alpha_i}{\sum_{j=1}^k \alpha_j}$。</p>
<p>将多项分布作为似然函数，得到</p>
<p>$$P(X | \theta_1, \cdots, \theta_k) \propto \theta_1^{n_1}\cdots\theta_k^{n_k}$$</p>
<p>Dirichlet分布作为先验分布，得到</p>
<p>$$<br>
P(\theta_1, \cdots, \theta_k) \propto \theta_1^{\alpha_1 - 1}\cdots\theta_k^{\alpha_k - 1}<br>
$$</p>
<p>于是有</p>

$$
\begin{aligned}
P(\theta_1, \cdots, \theta_k | X) & \propto P(X|\theta_1, \cdots, \theta_k)P(\theta_1, \cdots, \theta_k) \\
& \propto \theta_1^{n_1}\cdots\theta_k^{n_k} \theta_1^{\alpha_1 - 1}\cdots\theta_k^{\alpha_k - 1} \\
& = \theta_1^{\alpha_1+n_1-1}\cdots\theta_k^{\alpha_k+n_k-1}
\end{aligned}
$$

<p>后验分布也服从Dirichlet分布，因此Dirichlet分布是多项分布的共轭先验分布。</p>
<h2>LDA模型</h2>
<p>LDA模型的参数：</p>
<ul>
<li>$\vec{\alpha}$：语料级别的参数，用于生成每篇文档的主题分布</li>
<li>$\vec{\beta}$：语料级别的参数，用于生成每个主题的词汇分布</li>
<li>$\Phi$：语料级别的参数，每个主题的词汇分布</li>
<li>$\Theta$：文档级别的参数，每个文档的主题分布</li>
<li>$z_{m,n}$：词级别的参数，每个词对应的主题</li>
</ul>
<p>LDA模型生成文档的过程：</p>
<ul>
<li>对于每个主题$z_k$（$k\in [1, K]$）
<ul>
<li>生成主题词汇分布$\vec{\phi}_k \sim Dir(\vec{\beta})$</li>
</ul>
</li>
<li>对于每篇文档$d_m$（$m \in [1, M]$）
<ul>
<li>生成文档主题分布$\vec{\theta}_m \sim Dir(\vec{\alpha})$</li>
<li>生成文档长度$N_m \sim Poiss(\xi)$</li>
<li>对于文档中的每个词$w_{m,n}$（$n \in [1, N_m]$）
<ul>
<li>生成主题$z_{m,n} \sim Mult(\vec{\theta}_m)$</li>
<li>生成词汇$w _ {m,n} \sim Mult(\vec{\phi} _ {z _ {m,n}})$</li>
</ul>
</li>
</ul>
</li>
</ul>
<p>第$m$篇文档中的第$n$个词是$t$的概率为</p>

$$P\left(w_{m, n}=t | \vec{\theta}_{m}, \Phi\right)=\sum_{k=1}^{K} P\left(w_{m, n}=t | \vec{\phi}_{k}\right) P\left(z_{m, n}=k | \vec{\theta}_{m}\right)$$

<p>文档$m$中词、隐变量和参数的联合概率分布为</p>

$$P\left(\vec{w}_{m}, \vec{z}_{m}, \vec{\theta}_{m}, \Phi | \vec{\alpha}, \vec{\beta}\right)=P\left(\vec{\theta}_{m} | \vec{\alpha}\right) P(\Phi | \vec{\beta}) \prod_{n=1}^{N_{m}} P\left(w_{m, n} | \vec{\phi}_{z_{m, n}}\right) P\left(z_{m, n} | \vec{\theta}_{m}\right)$$

<p>所有文档的联合概率分布为</p>

$$P(\mathcal{W}, \mathcal{Z}, \Theta, \Phi | \vec{\alpha}, \vec{\beta})=\prod_{k=1}^{K} P\left(\vec{\phi}_{k} | \vec{\beta}\right) \prod_{m=1}^{M}\left(P\left(\vec{\theta}_{m} | \vec{\alpha}\right) \prod_{n=1}^{N_{m}} P\left(w_{m, n} | \vec{\phi}_{z_{m, n}}\right) P\left(z_{m, n} | \vec{\theta}_{m}\right)\right)$$

<h2>Gibbs采样</h2>
<p>Gibbs采样是一种特殊的马尔科夫链采样方法。已知观测值为$y$，给定一个带有参数的向量$\theta = (\theta_1, \theta_2, \cdots, \theta_d)$，若$\theta_j^t$表示$\theta_j$在第$t$次迭代的采样值，则该采样值随机地取自概率分布$p(\theta_j^t | \theta_1^t, \cdots, \theta_{j-1}^t, \theta_{j+1}^{t-1}, \cdots, \theta_{d}^{t-1}, y)$。</p>
<h2>用Gibbs采样训练LDA模型</h2>
<h3>求解联合概率</h3>
<p>由于$\Theta$和$\Phi$分别是由$\alpha$和$\beta$生成的，因此可以将$P(\mathcal{W}, \mathcal{Z}, \Theta, \Phi | \vec{\alpha}, \vec{\beta})$分解为</p>
<p>$$<br>
P(\mathcal{W}, \mathcal{Z}, \Theta, \Phi | \vec{\alpha}, \vec{\beta}) = P(\mathcal{W}, \mathcal{Z}| \vec{\alpha}, \vec{\beta}) = P(\mathcal{W}| \mathcal{Z}, \vec{\beta}) P(\mathcal{Z}| \vec{\alpha})<br>
$$</p>
<p>其中$P(\mathcal{W}| \mathcal{Z}, \vec{\beta})$表示根据确定的主题$\mathcal{Z}$和词分布的先验分布参数$\vec{\beta}$采样词的过程，$P(\mathcal{Z}| \vec{\alpha})$表示根据主题分布的先验分布参数$\vec{\alpha}$采样主题的过程，这两者是独立的，可以分别计算。</p>

$$
\begin{aligned}
P(\mathcal{W}| \mathcal{Z}, \vec{\beta}) =& \int P(\mathcal{W}| \mathcal{Z}, \Phi) P(\Phi | \vec{\beta}) d\Phi
\end{aligned}
$$

<p>由于文档中每个词的生成是独立的，且每个词都服从多项分布，因此$P(\mathcal{W}| \mathcal{Z}, \Phi)$可以写成每个主题中每个词出现的概率的乘积，即</p>

$$
\begin{aligned}
P(\mathcal{W}| \mathcal{Z}, \Phi) =& \prod_{m=1}^M \prod_{n=1}^{N_m} P(w_{m,n} | \vec{\phi}_{z_{m,n}}) \\
=& \prod_{k=1}^K \prod_{t=1}^V \phi_{k,t}^{n_{\cdot,k,t}}
\end{aligned}
$$

<p>其中$n_{\cdot,k,t}$表示主题$k$中词$t$的出现次数。</p>
<p>由于$\vec{\phi}_k \sim Dir(\vec{\beta})$，有</p>
<p>$$<br>
P(\Phi | \vec{\beta}) = \frac{1}{\Delta(\vec{\beta})} \prod_{k=1}^K \prod_{t=1}^V \phi_{k,t}^{\beta_t - 1}<br>
$$</p>
<p>则</p>

$$
\begin{aligned}
P(\mathcal{W}| \mathcal{Z}, \vec{\beta}) =& \int P(\mathcal{W}| \mathcal{Z}, \Phi) P(\Phi | \vec{\beta}) d\Phi \\
=& \int \prod_{k=1}^K \prod_{t=1}^V \phi_{k,t}^{n_{\cdot,k,t}} \frac{1}{\Delta(\vec{\beta})} \prod_{k=1}^K \prod_{t=1}^V \phi_{k,t}^{\beta_t - 1} d\Phi \\
=& \int \prod_{k=1}^K \prod_{t=1}^V \frac{1}{\Delta(\vec{\beta})} \phi_{k,t}^{n_{\cdot,k,t} + \beta_t - 1} d\Phi \\
=& \prod_{k=1}^K \frac{\Delta(\vec{n}_k + \vec{\beta})}{\Delta(\vec{\beta})}
\end{aligned}
$$

<p>其中$\vec{n} _ k = [n _ {\cdot,k,t}], t=1,\cdots,V$。</p>
<p>$P(\mathcal{Z}| \vec{\alpha})$也可以用同样的方法计算：</p>
<p>$$<br>
P(\mathcal{Z}| \vec{\alpha}) = \int P(\mathcal{Z} | \Theta) P(\Theta | \vec{\alpha}) d\Theta<br>
$$</p>
<p>其中</p>

$$
\begin{aligned}
P(\mathcal{Z} | \Theta) =& \prod_{m=1}^M \prod_{n=1}^{N_m} P(z_{m,n} | d_m) \\
=& \prod_{m=1}^M \prod_{k=1}^K \theta_{m,k}^{n_{m,k,\cdot}}
\end{aligned}
$$

<p>$n_{m,k,\cdot}$是主题$k$在文章$m$中出现的次数。</p>
<p>由于$\vec{\theta}_k \sim Dir(\vec{\alpha})$，有</p>
<p>$$<br>
P(\Theta | \vec{\alpha}) = \frac{1}{\Delta(\vec{\alpha})} \prod_{m=1}^M \prod_{k=1}^K \theta_{m,k}^{\alpha_k - 1}<br>
$$</p>
<p>因此</p>

$$
\begin{aligned}
P(\mathcal{Z}| \vec{\alpha}) =& \int P(\mathcal{Z} | \Theta) P(\Theta | \vec{\alpha}) d\Theta \\
=& \int \prod_{m=1}^M \prod_{k=1}^K \theta_{m,k}^{n_{m,k,\cdot}} \frac{1}{\Delta(\vec{\alpha})} \prod_{m=1}^M \prod_{k=1}^K \theta_{m,k}^{\alpha_k - 1} d\Theta \\
=& \int \prod_{m=1}^M \prod_{k=1}^K \frac{1}{\Delta(\vec{\alpha})} \theta_{m,k}^{n_{m,k,\cdot} + \alpha_k - 1} d\Theta \\
=& \prod_{m=1}^M \frac{\Delta(\vec{n}_m + \vec{\alpha})}{\Delta(\vec{\alpha})}
\end{aligned}
$$

<p>其中$\vec{n} _ m = [n _ {m,k,\cdot}], k=1,\cdots,K$。</p>
<p>综上可得</p>

$$
\begin{aligned}
P(\mathcal{W}, \mathcal{Z}| \vec{\alpha}, \vec{\beta}) =& P(\mathcal{W}| \mathcal{Z}, \vec{\beta}) P(\mathcal{Z}| \vec{\alpha}) \\
=& \prod_{k=1}^K \frac{\Delta(\vec{n}_k + \vec{\beta})}{\Delta(\vec{\beta})} \prod_{m=1}^M \frac{\Delta(\vec{n}_m + \vec{\alpha})}{\Delta(\vec{\alpha})}
\end{aligned}
$$

<h3>计算后验分布</h3>
<p>下面根据联合分布$P(\mathcal{W}, \mathcal{Z})$求解后验分布$P(\mathcal{Z} | \mathcal{W})$。根据Gibbs取样的思路，我们需要逐一排除每个词的主题分配，再根据其他词的主题分配和观察到的单词计算当前词的主题，即求解$P\left(z_{m, n}=k | \mathcal{Z}^{\neg m, n}, \mathcal{W}\right)$。</p>

$$
\begin{aligned}
& P\left(z_{m, n}=k | \mathcal{Z}^{\neg m, n}, \mathcal{W}\right) \\
=& \frac{P(\mathcal{Z}, \mathcal{W})}{P(\mathcal{Z}^{\neg m, n}, \mathcal{W})} \\
=& \frac{\prod_{k=1}^K \frac{\Delta(\vec{n}_k + \vec{\beta})}{\Delta(\vec{\beta})} \prod_{m=1}^M \frac{\Delta(\vec{n}_m + \vec{\alpha})}{\Delta(\vec{\alpha})}}{\prod_{k=1}^K \frac{\Delta(\vec{n}_k^{\neg m, n} + \vec{\beta})}{\Delta(\vec{\beta})} \prod_{m=1}^M \frac{\Delta(\vec{n}_m^{\neg m, n} + \vec{\alpha})}{\Delta(\vec{\alpha})}} \\
=& \frac{\Delta(\vec{n}_k + \vec{\beta})}{\Delta(\vec{n}_k^{\neg m, n} + \vec{\beta})} \frac{\Delta(\vec{n}_k + \vec{\alpha})}{\Delta(\vec{n}_k^{\neg m, n} + \vec{\alpha})} \\
=& \frac{\Gamma\left(n_{\cdot,k,t}+\beta_{t}\right) \Gamma\left(\sum_{t=1}^{V} n_{\cdot, k, t}^{\neg m, n}+\beta_{t}\right)}{\Gamma\left(n_{\cdot, k, t}^{\neg m, n}+\beta_{t}\right) \Gamma\left(\sum_{t=1}^{V} n_{\cdot, k, t}+\beta_{t}\right)} \frac{\Gamma\left(n_{m, k, \cdot},+\alpha_{k}\right) \Gamma\left(\sum_{k=1}^{K} n_{m, k,\cdot}^{\neg m, n}+\alpha_{k}\right)}{\Gamma\left(n_{m, k, t}^{\neg m, n}+\alpha_{k}\right) \Gamma\left(\sum_{k=1}^{K} n_{m, k, \cdot}+\alpha_{k}\right)} \\
=& \frac{n_{\cdot, k, t}^{\neg m, n} +\beta_{t}-1}{\left[\sum_{t=1}^{V} n_{\cdot, k, t}^{\neg m, n}+\beta_{t}\right]-1} \frac{n_{m, k, \cdot}^{\neg m, n}+\alpha_{k}-1}{\left[\sum_{k=1}^{K} n_{m, k,\cdot}^{\neg m, n}+\alpha_{k}\right]-1} \\
\propto& \frac{n_{\cdot, k, t}^{\neg m, n} +\beta_{t}-1}{\left[\sum_{t=1}^{V} n_{\cdot, k, t}^{\neg m, n}+\beta_{t}\right]-1} (n_{m, k, \cdot}^{\neg m, n}+\alpha_{k}-1)
\end{aligned}
$$

<h3>求解参数</h3>
<p>最后一步是求解$\Theta$和$\Phi$。</p>

$$P\left(\vec{\theta}_{m} | \vec{z}_{m}, \vec{\alpha}\right)=\frac{1}{Z_{\theta_{m}}} \prod_{n=1}^{N_{m}} P\left(z_{m, n} | \vec{\theta}_{m}\right) P\left(\vec{\theta}_{m} | \vec{\alpha}\right)=Dir\left(\vec{\theta}_{m} | \vec{n}_{m}+\vec{\alpha}\right)$$

$$P\left(\vec{\phi}_{k} | \mathcal{Z}, \mathcal{W}, \vec{\beta}\right)=\frac{1}{Z_{\phi_{k}}} \prod_{m, n: z_{m, n}=k} P\left(w_{m, n} | \vec{\phi}_{k}\right) P\left(\vec{\phi}_{k} | \vec{\beta}\right)=Dir\left(\vec{\phi}_{k} | \vec{n}_{k}+\vec{\beta}\right)$$

<p>求期望可得</p>

$$\hat{\theta}_{m, k}=\frac{n_{m, k, \cdot}+\alpha_{k}}{\sum_{k=1}^{K} n_{m, k, \cdot}+\alpha_{k}}$$

$$\hat{\phi}_{k, t}=\frac{n_{\cdot,k,t}+\beta_{t}}{\sum_{t=1}^{V} n_{\cdot, k, t}+\beta_{t}}$$

<h3>算法</h3>
<ul>
<li>将$n_{m, k, \cdot}$和$n_{\cdot,k,t}$初始化为0</li>
<li>令$\alpha_i = 50/K$，$\beta_i = 0.01$</li>
<li>随机初始化$z_{m,n}$</li>
<li>计算$n_{m, k, \cdot}$和$n_{\cdot,k,t}$</li>
<li>重复下列步骤
<ul>
<li>$m = 1\cdots M$
<ul>
<li>$n = 1 \cdots N_m$
<ul>
<li>$n_{m, z_{m,n}, \cdot} = n_{m, z_{m,n}, \cdot} - 1$</li>
<li>$n_{\cdot,z_{m,n},w_{m,n}} = n_{\cdot,z_{m,n},w_{m,n}} - 1$</li>
<li>根据后验分布$P\left(z_{m, n}=k | \mathcal{Z}^{\neg m, n}, \mathcal{W}\right)$采样得到$z_k$</li>
<li>$n_{m, k, \cdot} = n_{m, k, \cdot} + 1$</li>
<li>$n_{\cdot,k,w_{m,n}} = n_{\cdot,k,w_{m,n}} + 1$</li>
</ul>
</li>
</ul>
</li>
</ul>
</li>
<li>直到收敛</li>
<li>根据$n_{m, k, \cdot}$和$n_{\cdot,k,t}$计算$\Theta$和$\Phi$</li>
</ul>
<h3>似然函数</h3>
<p>似然函数为</p>

$$
\begin{aligned}
P\left(\mathcal{W} | \Theta, \Phi\right)=& \prod_m \prod_n \sum_{k=1}^{K} P\left(w_{m, n}=w | z_{m,n}=k, \phi_{k, w_{m,n}} \right) P\left(z_{m, n}=k | \theta_{m,k}\right) \\
=& \prod_m \prod_n \sum_{k=1}^{K} \phi_{k, w_{m,n}} \theta_{m,k}
\end{aligned}
$$

<p>对数似然为</p>

$$
\begin{aligned}
\log{P\left(\mathcal{W} | \Theta, \Phi\right)} =& \log{\prod_m \prod_n \sum_{k=1}^{K} \phi_{k, w_{m,n}} \theta_{m,k}} \\
=& \sum_{m} \sum_n \log{\sum_{k=1}^{K} \phi_{k, w_{m,n}} \theta_{m,k}}
\end{aligned}
$$

<h2>代码</h2>
<p><a href="https://github.com/zhanghuimeng/gibbs-lda" target="_blank" rel="noopener">Gibbs Sampling参考数据和代码</a></p>
<p>以ICLR 2018-2019年论文题目为输入文档，进行<code>K=3</code>，<code>max_step=1000</code>的Gibbs Sampling，得到3个主题如下：</p>
<figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br></pre></td><td class="code"><pre><span class="line">Topics:</span><br><span class="line">  Theme=0</span><br><span class="line">    word=for, prob=0.050888</span><br><span class="line">    word=neural, prob=0.041612</span><br><span class="line">    word=with, prob=0.032336</span><br><span class="line">    word=models, prob=0.012459</span><br><span class="line">    word=generative, prob=0.010339</span><br><span class="line">    word=using, prob=0.009809</span><br><span class="line">    word=training, prob=0.009809</span><br><span class="line">    word=unsupervised, prob=0.006893</span><br><span class="line">    word=optimization, prob=0.006363</span><br><span class="line">    word=by, prob=0.005833</span><br><span class="line">  Theme=1</span><br><span class="line">    word=networks, prob=0.044695</span><br><span class="line">    word=and, prob=0.028752</span><br><span class="line">    word=deep, prob=0.028229</span><br><span class="line">    word=in, prob=0.023002</span><br><span class="line">    word=the, prob=0.022741</span><br><span class="line">    word=a, prob=0.019866</span><br><span class="line">    word=reinforcement, prob=0.009411</span><br><span class="line">    word=from, prob=0.008627</span><br><span class="line">    word=representations, prob=0.007059</span><br><span class="line">    word=through, prob=0.004968</span><br><span class="line">  Theme=2</span><br><span class="line">    word=learning, prob=0.063051</span><br><span class="line">    word=of, prob=0.031916</span><br><span class="line">    word=to, prob=0.017646</span><br><span class="line">    word=adversarial, prob=0.016867</span><br><span class="line">    word=via, prob=0.014273</span><br><span class="line">    word=on, prob=0.011938</span><br><span class="line">    word=network, prob=0.009343</span><br><span class="line">    word=recurrent, prob=0.007527</span><br><span class="line">    word=an, prob=0.006230</span><br><span class="line">    word=variational, prob=0.006230</span><br></pre></td></tr></table></figure>
<p>可以看出，第一个主题因为没有去除停用词难以看出指向，第二个和第三个主题则分别是关于神经网络和学习的。</p>
<p>采样过程中，对数似然变化如下图所示：</p>
<p><img src="ll_k-3_step-1000.png" alt="对数似然的变化"></p>
<h2>参考文献</h2>
<ul>
<li><a href="https://blog.csdn.net/v_july_v/article/details/41209515" target="_blank" rel="noopener">通俗理解LDA主题模型</a></li>
<li><a href="https://www.jianshu.com/p/bb7bce40a15a" target="_blank" rel="noopener">共轭先验、共轭分布——为LDA做准备</a></li>
<li><a href="https://zhuanlan.zhihu.com/p/25072161" target="_blank" rel="noopener">浅谈「Gibbs采样」</a></li>
</ul>

      </div>
        
          <section class='meta' id="footer-meta">
            <hr>
            <div class='new-meta-box'>
              
                <div class="new-meta-item date" itemprop="dateUpdated" datetime="2020-03-18T20:39:56+00:00">
                  <a class='notlink'>
                    <i class="fas fa-save" aria-hidden="true"></i>
                    2020-03-18
                  </a>
                </div>
              
              
              
            </div>
          </section>
        

        
            <div class="prev-next">
                
                    <section class="prev">
                        <span class="art-item-left">
                            <h6><i class="fas fa-chevron-left" aria-hidden="true"></i>&nbsp;上一页</h6>
                            <h4>
                                <a href="/post/prml-chap-11-sampling-methods/" rel="prev" title="PRML读书笔记：第11章 采样方法">
                                  
                                      PRML读书笔记：第11章 采样方法
                                  
                                </a>
                            </h4>
                            
                                
                                <h6 class="tags">
                                    <a class="tag" href="/tags/Machine-Learning/"><i class="fas fa-hashtag fa-fw" aria-hidden="true"></i>Machine Learning</a> <a class="tag" href="/tags/PRML/"><i class="fas fa-hashtag fa-fw" aria-hidden="true"></i>PRML</a>
                                </h6>
                            
                        </span>
                    </section>
                
                
                    <section class="next">
                        <span class="art-item-right" aria-hidden="true">
                            <h6>下一页&nbsp;<i class="fas fa-chevron-right" aria-hidden="true"></i></h6>
                            <h4>
                                <a href="/post/prml-chap-9-2-mixtures-of-gaussians/" rel="prev" title="PRML读书笔记：9.2 混合高斯">
                                    
                                        PRML读书笔记：9.2 混合高斯
                                    
                                </a>
                            </h4>
                            
                                
                                <h6 class="tags">
                                    <a class="tag" href="/tags/Machine-Learning/"><i class="fas fa-hashtag fa-fw" aria-hidden="true"></i>Machine Learning</a> <a class="tag" href="/tags/PRML/"><i class="fas fa-hashtag fa-fw" aria-hidden="true"></i>PRML</a>
                                </h6>
                            
                        </span>
                    </section>
                
            </div>
        

    </section>

</article>

<!-- 根据页面mathjax变量决定是否加载MathJax数学公式js -->

    <!-- MathJax配置，可通过单美元符号书写行内公式等 -->
<script type="text/x-mathjax-config">
  MathJax.Hub.Config({
    "HTML-CSS": {
      preferredFont: "TeX",
      availableFonts: ["STIX","TeX"],
      linebreaks: { automatic:true },
      EqnChunk: (MathJax.Hub.Browser.isMobile ? 10 : 50)
    },
    tex2jax: {
      inlineMath: [ ["$", "$"], ["\\(","\\)"] ],
      processEscapes: true,
      ignoreClass: "tex2jax_ignore|dno",
      skipTags: ['script', 'noscript', 'style', 'textarea', 'pre', 'code']
    },
    TeX: {
      equationNumbers: { autoNumber: "AMS" },
      noUndefined: { attributes: { mathcolor: "red", mathbackground: "#FFEEEE", mathsize: "90%" } },
      Macros: { href: "{}" }
    },
    messageStyle: "none"
  });
</script>
<!-- 给MathJax元素添加has-jax class -->
<script type="text/x-mathjax-config">
  MathJax.Hub.Queue(function() {
    var all = MathJax.Hub.getAllJax(), i;
    for(i=0; i < all.length; i += 1) {
      all[i].SourceElement().parentNode.className += (all[i].SourceElement().parentNode.className ? ' ' : '') + 'has-jax';
    }
    console.log("mathjax did loaded!");
  });
</script>
<!-- 通过连接CDN加载MathJax的js代码 -->
<script type="text/javascript" async
  src="https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.1/MathJax.js?config=TeX-MML-AM_CHTML">
</script>



<br>

<!-- 显示推荐文章和评论 -->



  <article class="post white-box comments">
    <section class="article typo">
      <h4><i class="fas fa-comments fa-fw" aria-hidden="true"></i>&nbsp;评论</h4>
      
      
        <section id="comments">
          <div id="lv-container" data-id="city" data-uid="MTAyMC80MjgyNi8xOTM3Mw==">
            <noscript><div><i class='fas fa-exclamation-triangle'>&nbsp;无法加载Livere评论系统，请确保您的网络能够正常访问。</div></noscript>
          </div>
        </section>
      
      
    </section>
  </article>



<script>
    window.subData = {
        title: '用Gibbs采样训练LDA模型',
        tools: true
    }
</script>


        </div>
        <aside class='l_side'>
            
  
  
    
      
      
        <section class='author'>
  <div class='content pure'>
    
    
    
      <div class="social-wrapper">
        
          
            <a href="mailto:zhanghuimeng1997@gmail.com" class="social flat-btn" target="_blank" rel="external"><i class="social fas fa-envelope" aria-hidden="true"></i></a>
          
        
          
            <a href="https://github.com/zhanghuimeng" class="social flat-btn" target="_blank" rel="external"><i class="social fab fa-github" aria-hidden="true"></i></a>
          
        
          
            <a href="https://music.163.com/#/user/home?id=261028414" class="social flat-btn" target="_blank" rel="external"><i class="social fas fa-music" aria-hidden="true"></i></a>
          
        
      </div>
    
  </div>
</section>

      
    
  
    
      
      
        
  <section class='toc-wrapper'>
    
<header class='pure'>
  <div><i class="fas fa-list fa-fw" aria-hidden="true"></i>&nbsp;&nbsp;文章目录</div>
  
    <div class='wrapper'><a class="s-toc rightBtn" rel="external nofollow noopener noreferrer" href="javascript:void(0)"><i class="fas fa-thumbtack fa-fw"></i></a></div>
  
</header>

    <div class='content pure'>
      <ol class="toc"><li class="toc-item toc-level-2"><a class="toc-link" href="#undefined"><span class="toc-text">数学基础</span></a><ol class="toc-child"><li class="toc-item toc-level-3"><a class="toc-link" href="#undefined"><span class="toc-text">二项分布</span></a></li><li class="toc-item toc-level-3"><a class="toc-link" href="#undefined"><span class="toc-text">二项分布的共轭先验分布：Beta分布</span></a></li><li class="toc-item toc-level-3"><a class="toc-link" href="#undefined"><span class="toc-text">多项分布</span></a></li><li class="toc-item toc-level-3"><a class="toc-link" href="#undefined"><span class="toc-text">多项分布的共轭先验分布：Dirichlet分布</span></a></li></ol></li><li class="toc-item toc-level-2"><a class="toc-link" href="#undefined"><span class="toc-text">LDA模型</span></a></li><li class="toc-item toc-level-2"><a class="toc-link" href="#undefined"><span class="toc-text">Gibbs采样</span></a></li><li class="toc-item toc-level-2"><a class="toc-link" href="#undefined"><span class="toc-text">用Gibbs采样训练LDA模型</span></a><ol class="toc-child"><li class="toc-item toc-level-3"><a class="toc-link" href="#undefined"><span class="toc-text">求解联合概率</span></a></li><li class="toc-item toc-level-3"><a class="toc-link" href="#undefined"><span class="toc-text">计算后验分布</span></a></li><li class="toc-item toc-level-3"><a class="toc-link" href="#undefined"><span class="toc-text">求解参数</span></a></li><li class="toc-item toc-level-3"><a class="toc-link" href="#undefined"><span class="toc-text">算法</span></a></li><li class="toc-item toc-level-3"><a class="toc-link" href="#undefined"><span class="toc-text">似然函数</span></a></li></ol></li><li class="toc-item toc-level-2"><a class="toc-link" href="#undefined"><span class="toc-text">代码</span></a></li><li class="toc-item toc-level-2"><a class="toc-link" href="#undefined"><span class="toc-text">参考文献</span></a></li></ol>
    </div>
  </section>


      
    
  
    
      
      
        
  <section class='category'>
    
<header class='pure'>
  <div><i class="fas fa-folder-open fa-fw" aria-hidden="true"></i>&nbsp;&nbsp;所有分类</div>
  
</header>

    <div class='content pure'>
      <ul class="entry">
        
          <li><a class="flat-box" title="/categories/Blogging/" href="/categories/Blogging/"><div class='name'>Blogging</div><div class='badge'>(2)</div></a></li>
        
          <li><a class="flat-box" title="/categories/Codeforces/" href="/categories/Codeforces/"><div class='name'>Codeforces</div><div class='badge'>(4)</div></a></li>
        
          <li><a class="flat-box" title="/categories/Leetcode/" href="/categories/Leetcode/"><div class='name'>Leetcode</div><div class='badge'>(32)</div></a></li>
        
          <li><a class="flat-box" title="/categories/MLDS/" href="/categories/MLDS/"><div class='name'>MLDS</div><div class='badge'>(0)</div></a></li>
        
          <li><a class="flat-box" title="/categories/NLP/" href="/categories/NLP/"><div class='name'>NLP</div><div class='badge'>(5)</div></a></li>
        
          <li><a class="flat-box" title="/categories/USACO/" href="/categories/USACO/"><div class='name'>USACO</div><div class='badge'>(5)</div></a></li>
        
          <li><a class="flat-box" title="/categories/博客/" href="/categories/博客/"><div class='name'>博客</div><div class='badge'>(0)</div></a></li>
        
          <li><a class="flat-box" title="/categories/旧博客/" href="/categories/旧博客/"><div class='name'>旧博客</div><div class='badge'>(2)</div></a></li>
        
          <li><a class="flat-box" title="/categories/机器学习/" href="/categories/机器学习/"><div class='name'>机器学习</div><div class='badge'>(2)</div></a></li>
        
          <li><a class="flat-box" title="/categories/深度学习/" href="/categories/深度学习/"><div class='name'>深度学习</div><div class='badge'>(0)</div></a></li>
        
          <li><a class="flat-box" title="/categories/读书笔记/" href="/categories/读书笔记/"><div class='name'>读书笔记</div><div class='badge'>(16)</div></a></li>
        
          <li><a class="flat-box" title="/categories/随笔/" href="/categories/随笔/"><div class='name'>随笔</div><div class='badge'>(3)</div></a></li>
        
      </ul>
    </div>
  </section>


      
    
  
    
      
      
        
  <section class='tagcloud'>
    
<header class='pure'>
  <div><i class="fas fa-hashtag fa-fw" aria-hidden="true"></i>&nbsp;&nbsp;热门标签</div>
  
</header>

    <div class='content pure'>
      <a href="/tags/A-Munday/" style="font-size: 14px; color: #999">A.Munday</a> <a href="/tags/Blogging/" style="font-size: 14px; color: #999">Blogging</a> <a href="/tags/C-Marlowe/" style="font-size: 14px; color: #999">C.Marlowe</a> <a href="/tags/CSP/" style="font-size: 15.07px; color: #929292">CSP</a> <a href="/tags/Codeforces/" style="font-size: 19.36px; color: #757575">Codeforces</a> <a href="/tags/Codeforces-Contest/" style="font-size: 19px; color: #777">Codeforces Contest</a> <a href="/tags/Counseling/" style="font-size: 14px; color: #999">Counseling</a> <a href="/tags/Cryptography/" style="font-size: 14px; color: #999">Cryptography</a> <a href="/tags/D-Drayton/" style="font-size: 14px; color: #999">D.Drayton</a> <a href="/tags/Deep-Learning/" style="font-size: 15.07px; color: #929292">Deep Learning</a> <a href="/tags/Depth-first-Search/" style="font-size: 14px; color: #999">Depth-first Search</a> <a href="/tags/Deutsch/" style="font-size: 14px; color: #999">Deutsch</a> <a href="/tags/DigitCircuit/" style="font-size: 14px; color: #999">DigitCircuit</a> <a href="/tags/E-Vere/" style="font-size: 14px; color: #999">E. Vere</a> <a href="/tags/E-Spencer/" style="font-size: 14px; color: #999">E.Spencer</a> <a href="/tags/Essay/" style="font-size: 14.36px; color: #979797">Essay</a> <a href="/tags/Flask/" style="font-size: 14px; color: #999">Flask</a> <a href="/tags/Github/" style="font-size: 14.71px; color: #949494">Github</a> <a href="/tags/GoldenTreasury/" style="font-size: 23.29px; color: #5a5a5a">GoldenTreasury</a> <a href="/tags/Google-Analytics/" style="font-size: 14px; color: #999">Google Analytics</a> <a href="/tags/H-Constable/" style="font-size: 14px; color: #999">H.Constable</a> <a href="/tags/Hexo/" style="font-size: 14px; color: #999">Hexo</a> <a href="/tags/J-Donne/" style="font-size: 14px; color: #999">J.Donne</a> <a href="/tags/J-Lyly/" style="font-size: 14px; color: #999">J.Lyly</a> <a href="/tags/J-Sylvester/" style="font-size: 14px; color: #999">J.Sylvester</a> <a href="/tags/J-Webster/" style="font-size: 14px; color: #999">J.Webster</a> <a href="/tags/Leetcode/" style="font-size: 24px; color: #555">Leetcode</a> <a href="/tags/Leetcode-Contest/" style="font-size: 23.64px; color: #575757">Leetcode Contest</a> <a href="/tags/Lyric/" style="font-size: 17.21px; color: #838383">Lyric</a> <a href="/tags/Machine-Learning/" style="font-size: 19.36px; color: #757575">Machine Learning</a> <a href="/tags/Machine-Translation/" style="font-size: 16.5px; color: #888">Machine Translation</a> <a href="/tags/Maths/" style="font-size: 14px; color: #999">Maths</a> <a href="/tags/NLP/" style="font-size: 14px; color: #999">NLP</a> <a href="/tags/Natural-Language-Processing/" style="font-size: 17.21px; color: #838383">Natural Language Processing</a> <a href="/tags/OS/" style="font-size: 21.14px; color: #686868">OS</a> <a href="/tags/OSTEP/" style="font-size: 17.93px; color: #7e7e7e">OSTEP</a> <a href="/tags/Old-Blog/" style="font-size: 14px; color: #999">Old Blog</a> <a href="/tags/OldBlog/" style="font-size: 14.71px; color: #949494">OldBlog</a> <a href="/tags/P-Sidney/" style="font-size: 14px; color: #999">P.Sidney</a> <a href="/tags/PRML/" style="font-size: 18.29px; color: #7c7c7c">PRML</a> <a href="/tags/Paper/" style="font-size: 16.5px; color: #888">Paper</a> <a href="/tags/Paul-Simon/" style="font-size: 14px; color: #999">Paul Simon</a> <a href="/tags/PhysicsExperiment/" style="font-size: 14px; color: #999">PhysicsExperiment</a> <a href="/tags/Psychology/" style="font-size: 14px; color: #999">Psychology</a> <a href="/tags/PyCharm/" style="font-size: 14px; color: #999">PyCharm</a> <a href="/tags/Quality-Estimation/" style="font-size: 15.43px; color: #8f8f8f">Quality Estimation</a> <a href="/tags/R-Barnfield/" style="font-size: 14px; color: #999">R.Barnfield</a> <a href="/tags/Raspberry-Pi/" style="font-size: 14px; color: #999">Raspberry Pi</a> <a href="/tags/Reading-Report/" style="font-size: 17.57px; color: #818181">Reading Report</a> <a href="/tags/S-Daniel/" style="font-size: 14px; color: #999">S.Daniel</a> <a href="/tags/SGU/" style="font-size: 14.36px; color: #979797">SGU</a> <a href="/tags/Sonnet/" style="font-size: 19.71px; color: #727272">Sonnet</a> <a href="/tags/Spokes/" style="font-size: 14.71px; color: #949494">Spokes</a> <a href="/tags/SystemAnalysis-Control/" style="font-size: 14px; color: #999">SystemAnalysis&Control</a> <a href="/tags/T-Dekker/" style="font-size: 14px; color: #999">T.Dekker</a> <a href="/tags/T-Heywood/" style="font-size: 14px; color: #999">T.Heywood</a> <a href="/tags/T-Lodge/" style="font-size: 14px; color: #999">T.Lodge</a> <a href="/tags/T-Nashe/" style="font-size: 14px; color: #999">T.Nashe</a> <a href="/tags/T-Wyatt/" style="font-size: 14px; color: #999">T.Wyatt</a> <a href="/tags/THUMT/" style="font-size: 15.79px; color: #8d8d8d">THUMT</a> <a href="/tags/TensorFlow/" style="font-size: 15.07px; color: #929292">TensorFlow</a> <a href="/tags/Translation/" style="font-size: 18.64px; color: #797979">Translation</a> <a href="/tags/Tree/" style="font-size: 14px; color: #999">Tree</a> <a href="/tags/USACO/" style="font-size: 22.21px; color: #616161">USACO</a> <a href="/tags/W-Alexander/" style="font-size: 14px; color: #999">W.Alexander</a> <a href="/tags/W-Drummond/" style="font-size: 15.07px; color: #929292">W.Drummond</a> <a href="/tags/W-Shakespeare/" style="font-size: 21.5px; color: #666">W.Shakespeare</a> <a href="/tags/WebStorm/" style="font-size: 14px; color: #999">WebStorm</a> <a href="/tags/object-Object/" style="font-size: 14px; color: #999">[object Object]</a> <a href="/tags/alg-Ad-Hoc/" style="font-size: 14.36px; color: #979797">alg:Ad-Hoc</a> <a href="/tags/alg-Aho–Corasick-Algorithm/" style="font-size: 14px; color: #999">alg:Aho–Corasick Algorithm</a> <a href="/tags/alg-Array/" style="font-size: 20.79px; color: #6b6b6b">alg:Array</a> <a href="/tags/alg-Automata/" style="font-size: 14px; color: #999">alg:Automata</a> <a href="/tags/alg-Backtracking/" style="font-size: 15.79px; color: #8d8d8d">alg:Backtracking</a> <a href="/tags/alg-Binary-Indexed-Tree/" style="font-size: 14px; color: #999">alg:Binary Indexed Tree</a> <a href="/tags/alg-Binary-Search/" style="font-size: 16.5px; color: #888">alg:Binary Search</a> <a href="/tags/alg-Binary-Search-Tree/" style="font-size: 16.86px; color: #868686">alg:Binary Search Tree</a> <a href="/tags/alg-Binary-Tree/" style="font-size: 14px; color: #999">alg:Binary Tree</a> <a href="/tags/alg-Binray-Search/" style="font-size: 14px; color: #999">alg:Binray Search</a> <a href="/tags/alg-Bit-Manipulation/" style="font-size: 15.43px; color: #8f8f8f">alg:Bit Manipulation</a> <a href="/tags/alg-Bitmasks/" style="font-size: 14px; color: #999">alg:Bitmasks</a> <a href="/tags/alg-Breadth-First-Search/" style="font-size: 14px; color: #999">alg:Breadth-First Search</a> <a href="/tags/alg-Breadth-first-Search/" style="font-size: 18.29px; color: #7c7c7c">alg:Breadth-first Search</a> <a href="/tags/alg-Breadth-firth-Search/" style="font-size: 14.36px; color: #979797">alg:Breadth-firth Search</a> <a href="/tags/alg-Brute-Force/" style="font-size: 17.21px; color: #838383">alg:Brute Force</a> <a href="/tags/alg-Centroid-Decomposition/" style="font-size: 14px; color: #999">alg:Centroid Decomposition</a> <a href="/tags/alg-Depth-first-Search/" style="font-size: 20.07px; color: #707070">alg:Depth-first Search</a> <a href="/tags/alg-Divide-and-Conquer/" style="font-size: 14px; color: #999">alg:Divide and Conquer</a> <a href="/tags/alg-Dynamic-Porgramming/" style="font-size: 14px; color: #999">alg:Dynamic Porgramming</a> <a href="/tags/alg-Dynamic-Programming/" style="font-size: 22.57px; color: #5f5f5f">alg:Dynamic Programming</a> <a href="/tags/alg-Games/" style="font-size: 14px; color: #999">alg:Games</a> <a href="/tags/alg-Geometry/" style="font-size: 14px; color: #999">alg:Geometry</a> <a href="/tags/alg-Graph/" style="font-size: 15.43px; color: #8f8f8f">alg:Graph</a> <a href="/tags/alg-Greedy/" style="font-size: 21.86px; color: #646464">alg:Greedy</a> <a href="/tags/alg-Hash-Table/" style="font-size: 19.71px; color: #727272">alg:Hash Table</a> <a href="/tags/alg-Heap/" style="font-size: 15.43px; color: #8f8f8f">alg:Heap</a> <a href="/tags/alg-In-Order-Traversal/" style="font-size: 14.36px; color: #979797">alg:In-Order Traversal</a> <a href="/tags/alg-Index-Search-Array/" style="font-size: 14px; color: #999">alg:Index Search Array</a> <a href="/tags/alg-Linked-List/" style="font-size: 15.79px; color: #8d8d8d">alg:Linked List</a> <a href="/tags/alg-Map/" style="font-size: 14px; color: #999">alg:Map</a> <a href="/tags/alg-Math/" style="font-size: 22.93px; color: #5c5c5c">alg:Math</a> <a href="/tags/alg-Matrix/" style="font-size: 14px; color: #999">alg:Matrix</a> <a href="/tags/alg-Meet-in-the-Middle/" style="font-size: 14.36px; color: #979797">alg:Meet in the Middle</a> <a href="/tags/alg-Minimax/" style="font-size: 14.36px; color: #979797">alg:Minimax</a> <a href="/tags/alg-Minmax/" style="font-size: 14px; color: #999">alg:Minmax</a> <a href="/tags/alg-Monotonic-Stack/" style="font-size: 16.14px; color: #8a8a8a">alg:Monotonic Stack</a> <a href="/tags/alg-Network-Flow/" style="font-size: 14px; color: #999">alg:Network Flow</a> <a href="/tags/alg-Priority-Queue/" style="font-size: 14px; color: #999">alg:Priority Queue</a> <a href="/tags/alg-Queue/" style="font-size: 14.71px; color: #949494">alg:Queue</a> <a href="/tags/alg-Rabin-Karp/" style="font-size: 14px; color: #999">alg:Rabin-Karp</a> <a href="/tags/alg-Random/" style="font-size: 14.71px; color: #949494">alg:Random</a> <a href="/tags/alg-Rank-Tree/" style="font-size: 14px; color: #999">alg:Rank Tree</a> <a href="/tags/alg-Recursion/" style="font-size: 15.43px; color: #8f8f8f">alg:Recursion</a> <a href="/tags/alg-Recursive/" style="font-size: 14.36px; color: #979797">alg:Recursive</a> <a href="/tags/alg-Rejection-Sampling/" style="font-size: 14px; color: #999">alg:Rejection Sampling</a> <a href="/tags/alg-Reservoir-Sampling/" style="font-size: 14px; color: #999">alg:Reservoir Sampling</a> <a href="/tags/alg-Segmentation-Tree/" style="font-size: 14px; color: #999">alg:Segmentation Tree</a> <a href="/tags/alg-Set/" style="font-size: 14px; color: #999">alg:Set</a> <a href="/tags/alg-Sliding-Window/" style="font-size: 14px; color: #999">alg:Sliding Window</a> <a href="/tags/alg-Sort/" style="font-size: 15.07px; color: #929292">alg:Sort</a> <a href="/tags/alg-Stack/" style="font-size: 19px; color: #777">alg:Stack</a> <a href="/tags/alg-String/" style="font-size: 19px; color: #777">alg:String</a> <a href="/tags/alg-Suffix-Array/" style="font-size: 14px; color: #999">alg:Suffix Array</a> <a href="/tags/alg-Suffix-Tree/" style="font-size: 14px; color: #999">alg:Suffix Tree</a> <a href="/tags/alg-Ternary-Search/" style="font-size: 14px; color: #999">alg:Ternary Search</a> <a href="/tags/alg-Topological-Sort/" style="font-size: 14px; color: #999">alg:Topological Sort</a> <a href="/tags/alg-Treap/" style="font-size: 14px; color: #999">alg:Treap</a> <a href="/tags/alg-Tree/" style="font-size: 20.43px; color: #6d6d6d">alg:Tree</a> <a href="/tags/alg-Trie/" style="font-size: 14.36px; color: #979797">alg:Trie</a> <a href="/tags/alg-Two-Pointers/" style="font-size: 17.93px; color: #7e7e7e">alg:Two Pointers</a> <a href="/tags/alg-Union-find-Forest/" style="font-size: 15.43px; color: #8f8f8f">alg:Union-find Forest</a> <a href="/tags/artist-Ceremony/" style="font-size: 14px; color: #999">artist:Ceremony</a> <a href="/tags/artist-Cruel-Hand/" style="font-size: 14.36px; color: #979797">artist:Cruel Hand</a> <a href="/tags/artist-Have-Heart/" style="font-size: 14px; color: #999">artist:Have Heart</a> <a href="/tags/artist-Johnny-Cash/" style="font-size: 14px; color: #999">artist:Johnny Cash</a> <a href="/tags/artist-Touche-Amore/" style="font-size: 14px; color: #999">artist:Touche Amore</a> <a href="/tags/artist-Wir-Sind-Helden/" style="font-size: 14.71px; color: #949494">artist:Wir Sind Helden</a> <a href="/tags/translation/" style="font-size: 14.36px; color: #979797">translation</a> <a href="/tags/ucore/" style="font-size: 14px; color: #999">ucore</a> <a href="/tags/付勇林/" style="font-size: 15.79px; color: #8d8d8d">付勇林</a> <a href="/tags/卞之琳/" style="font-size: 14px; color: #999">卞之琳</a> <a href="/tags/屠岸/" style="font-size: 16.14px; color: #8a8a8a">屠岸</a> <a href="/tags/戴镏龄/" style="font-size: 15.79px; color: #8d8d8d">戴镏龄</a> <a href="/tags/曹明伦/" style="font-size: 15.43px; color: #8f8f8f">曹明伦</a> <a href="/tags/朱生豪/" style="font-size: 17.57px; color: #818181">朱生豪</a> <a href="/tags/李霁野/" style="font-size: 15.07px; color: #929292">李霁野</a> <a href="/tags/杨熙龄/" style="font-size: 14px; color: #999">杨熙龄</a> <a href="/tags/林天斗/" style="font-size: 14px; color: #999">林天斗</a> <a href="/tags/梁宗岱/" style="font-size: 16.86px; color: #868686">梁宗岱</a> <a href="/tags/梁葆成/" style="font-size: 14px; color: #999">梁葆成</a> <a href="/tags/袁广达/" style="font-size: 14px; color: #999">袁广达</a> <a href="/tags/郭沫若/" style="font-size: 14px; color: #999">郭沫若</a> <a href="/tags/黄新渠/" style="font-size: 14px; color: #999">黄新渠</a>
    </div>
  </section>


      
    
  
    
      
      
        <section class='list'>
  
<header class='pure'>
  <div><i class="fas fa-link fa-fw" aria-hidden="true"></i>&nbsp;&nbsp;特别链接</div>
  
</header>

  <div class='content pure'>
    <ul class="entry">
      
        <li><a class="flat-box" title="https://wenj.github.io/" href="https://wenj.github.io/">
          <div class='name'>
            
              <i class="fas fa-comment-dots fa-fw" aria-hidden="true"></i>
            
            &nbsp;&nbsp;wenj
          </div>
          
        </a></li>
      
        <li><a class="flat-box" title="http://bellasong.site/" href="http://bellasong.site/">
          <div class='name'>
            
              <i class="fas fa-comment-dots fa-fw" aria-hidden="true"></i>
            
            &nbsp;&nbsp;ssh
          </div>
          
        </a></li>
      
    </ul>
  </div>
</section>

      
    
  


        </aside>
        <script>setLoadingBarProgress(60);</script>
    </div>
    <a class="s-top fas fa-arrow-up fa-fw" href='javascript:void(0)'></a>
    </div>
    <footer id="footer" class="clearfix">
  
  
    <div class="social-wrapper">
      
        
          <a href="mailto:zhanghuimeng1997@gmail.com" class="social fas fa-envelope flat-btn" target="_blank" rel="external"></a>
        
      
        
          <a href="https://github.com/zhanghuimeng" class="social fab fa-github flat-btn" target="_blank" rel="external"></a>
        
      
        
          <a href="https://music.163.com/#/user/home?id=261028414" class="social fas fa-music flat-btn" target="_blank" rel="external"></a>
        
      
    </div>
  
  <br>
  <div><p>博客内容遵循 <a href="https://creativecommons.org/licenses/by-nc-sa/4.0/deed.zh">署名-非商业性使用-相同方式共享 4.0 国际 (CC BY-NC-SA 4.0) 协议</a></p>
</div>
  <div>本站使用 <a href="https://xaoxuu.com/wiki/material-x/" target="_blank" class="codename">Material X</a> 作为主题，总访问量为 <span id="busuanzi_value_site_pv"><i class="fas fa-spinner fa-spin fa-fw" aria-hidden="true"></i></span> 次。
  </div>
</footer>

    <script>setLoadingBarProgress(80);</script>
    <script src="https://cdn.jsdelivr.net/npm/jquery@3.2.1/dist/jquery.min.js"></script>

  <script>
    var GOOGLE_CUSTOM_SEARCH_API_KEY = "";
    var GOOGLE_CUSTOM_SEARCH_ENGINE_ID = "";
    var ALGOLIA_API_KEY = "";
    var ALGOLIA_APP_ID = "";
    var ALGOLIA_INDEX_NAME = "";
    var AZURE_SERVICE_NAME = "";
    var AZURE_INDEX_NAME = "";
    var AZURE_QUERY_KEY = "";
    var BAIDU_API_ID = "";
    var SEARCH_SERVICE = "hexo" || "hexo";
    var ROOT = "/"||"/";
    if(!ROOT.endsWith('/'))ROOT += '/';
  </script>



  <script async src="https://cdn.jsdelivr.net/npm/scrollreveal@4.0.5/dist/scrollreveal.min.js"></script>
  <script type="text/javascript">
    $(function() {
      const $reveal = $('.reveal');
      if ($reveal.length === 0) return;
      const sr = ScrollReveal({ distance: 0 });
      sr.reveal('.reveal');
    });
  </script>


  <script src="https://cdn.jsdelivr.net/npm/node-waves@0.7.6/dist/waves.min.js"></script>
  <script type="text/javascript">
    $(function() {
      Waves.attach('.flat-btn', ['waves-button']);
      Waves.attach('.float-btn', ['waves-button', 'waves-float']);
      Waves.attach('.float-btn-light', ['waves-button', 'waves-float', 'waves-light']);
      Waves.attach('.flat-box', ['waves-block']);
      Waves.attach('.float-box', ['waves-block', 'waves-float']);
      Waves.attach('.waves-image');
      Waves.init();
    });
  </script>


  <script async src="https://cdn.jsdelivr.net/gh/xaoxuu/cdn-busuanzi@2.3/js/busuanzi.pure.mini.js"></script>







  <script type="text/javascript">
    (function(d, s) {
      var j, e = d.getElementsByTagName(s)[0];
      if (typeof LivereTower === 'function') { return; }
      j = d.createElement(s);
      j.src = 'https://cdn-city.livere.com/js/embed.dist.js';
      j.async = true;
      e.parentNode.insertBefore(j, e);
    })(document, 'script');
  </script>





  <script src="/js/app.js"></script>
<script src="/js/search.js"></script>





<!-- 复制 -->
<script src="https://cdn.jsdelivr.net/npm/clipboard@2/dist/clipboard.min.js"></script>
<script>
  let COPY_SUCCESS = "复制成功";
  let COPY_FAILURE = "复制失败";
  /*页面载入完成后，创建复制按钮*/
  !function (e, t, a) {
    /* code */
    var initCopyCode = function(){
      var copyHtml = '';
      copyHtml += '<button class="btn-copy" data-clipboard-snippet="">';
      copyHtml += '  <i class="fa fa-copy"></i><span>Copy</span>';
      copyHtml += '</button>';
      $(".highlight .code pre").before(copyHtml);
      var clipboard = new ClipboardJS('.btn-copy', {
        target: function(trigger) {
          return trigger.nextElementSibling;
        }
      });

      clipboard.on('success', function(e) {
        //您可以加入成功提示
        console.info('Action:', e.action);
        console.info('Text:', e.text);
        console.info('Trigger:', e.trigger);
        success_prompt(COPY_SUCCESS);
        e.clearSelection();
      });
      clipboard.on('error', function(e) {
        //您可以加入失败提示
        console.error('Action:', e.action);
        console.error('Trigger:', e.trigger);
        fail_prompt(COPY_FAILURE);
      });
    }
    initCopyCode();

  }(window, document);

  /**
   * 弹出式提示框，默认1.5秒自动消失
   * @param message 提示信息
   * @param style 提示样式，有alert-success、alert-danger、alert-warning、alert-info
   * @param time 消失时间
   */
  var prompt = function (message, style, time)
  {
      style = (style === undefined) ? 'alert-success' : style;
      time = (time === undefined) ? 1500 : time*1000;
      $('<div>')
          .appendTo('body')
          .addClass('alert ' + style)
          .html(message)
          .show()
          .delay(time)
          .fadeOut();
  };

  // 成功提示
  var success_prompt = function(message, time)
  {
      prompt(message, 'alert-success', time);
  };

  // 失败提示
  var fail_prompt = function(message, time)
  {
      prompt(message, 'alert-danger', time);
  };

  // 提醒
  var warning_prompt = function(message, time)
  {
      prompt(message, 'alert-warning', time);
  };

  // 信息提示
  var info_prompt = function(message, time)
  {
      prompt(message, 'alert-info', time);
  };

</script>


<!-- fancybox -->
<script src="https://cdn.jsdelivr.net/gh/fancyapps/fancybox@3.5.7/dist/jquery.fancybox.min.js"></script>
<script>
  let LAZY_LOAD_IMAGE = "";
  $(".article-entry").find("img").each(function () {
      var element = document.createElement("a");
      $(element).attr("data-fancybox", "gallery");
      $(element).attr("href", $(this).attr("src"));
      /* 图片采用懒加载处理时,
       * 一般图片标签内会有个属性名来存放图片的真实地址，比如 data-original,
       * 那么此处将原本的属性名src替换为对应属性名data-original,
       * 修改如下
       */
       if (LAZY_LOAD_IMAGE) {
         $(element).attr("href", $(this).attr("data-original"));
       }
      $(this).wrap(element);
  });
</script>





    <script>setLoadingBarProgress(100);</script><!-- hexo-inject:begin --><!-- hexo-inject:end -->
</body>
</html>
