<!DOCTYPE html>
<html>
<head>
  <!-- hexo-inject:begin --><!-- hexo-inject:end --><meta charset="utf-8">
  <meta http-equiv="X-UA-Compatible" content="IE=edge" />
  
  <title>THUMT代码详解（4）：infer阶段模型和数据流 | 张慕晖的博客</title>
  
  

  
  <link rel="alternate" href="/atom.xml" title="张慕晖的博客">
  

  <meta name="HandheldFriendly" content="True" />
  <meta name="apple-mobile-web-app-capable" content="yes">
  <meta name="viewport" content="width=device-width, initial-scale=1, maximum-scale=1">
  <!-- meta -->
  

  <!-- link -->
  <link rel="stylesheet" href="https://cdn.jsdelivr.net/gh/fancyapps/fancybox@3.5.7/dist/jquery.fancybox.min.css" />
  
  <link rel="stylesheet" href="https://cdn.jsdelivr.net/npm/node-waves@0.7.6/dist/waves.min.css">
  
  <link rel="stylesheet" href="https://cdn.jsdelivr.net/npm/@fortawesome/fontawesome-free@5.6.3/css/all.min.css">
  
  
  <link rel='stylesheet' href='https://cdnjs.cloudflare.com/ajax/libs/KaTeX/0.10.0/katex.min.css'>
  

  
  <link rel="shortcut icon" type='image/x-icon' href="/files/favicon.ico">
  

  
  <link rel="stylesheet" href="/style.css">
  

  <script>
    function setLoadingBarProgress(num) {
      document.getElementById('loading-bar').style.width=num+"%";
    }
  </script>

  
    <!-- Global site tag (gtag.js) - Google Analytics -->
    <script async src="https://www.googletagmanager.com/gtag/js?id=UA-119345306-1"></script>
    <script>
      window.dataLayer = window.dataLayer || [];
      function gtag(){dataLayer.push(arguments);}
      gtag('js', new Date());
      gtag('config', 'UA-119345306-1');
    </script><!-- hexo-inject:begin --><!-- hexo-inject:end -->
  
  
</head>

<body>
    <!-- hexo-inject:begin --><!-- hexo-inject:end --><div id="loading-bar-wrapper">
  <div id="loading-bar" class="pure"></div>
</div>

    <script>setLoadingBarProgress(20)</script>
    <header class="l_header pure">
	<div class='wrapper'>
		<div class="nav-main container container--flex">
      <a class="logo flat-box" href='/' >
        
          张慕晖的博客
        
      </a>
			<div class='menu'>
				<ul class='h-list'>
          
				</ul>
			</div>

			
				<div class="m_search">
					<form name="searchform" class="form u-search-form">
						<input type="text" class="input u-search-input" placeholder="搜索" />
						<span class="icon"><i class="fas fa-search fa-fw"></i></span>
					</form>
				</div>
			
			<ul class='switcher h-list'>
				
					<li class='s-search'><a class="fas fa-search fa-fw" href='javascript:void(0)'></a></li>
				
				<li class='s-menu'><a class="fas fa-bars fa-fw" href='javascript:void(0)'></a></li>
			</ul>
		</div>

		<div class='nav-sub container container--flex'>
			<a class="logo flat-box"></a>
			<ul class='switcher h-list'>
				<li class='s-comment'><a class="flat-btn fas fa-comments fa-fw" href='javascript:void(0)'></a></li>
				<li class='s-toc'><a class="flat-btn fas fa-list fa-fw" href='javascript:void(0)'></a></li>
			</ul>
		</div>
	</div>
</header>
	<aside class="menu-phone">
    <header>
		<nav class="menu">
      <ul>
          
      </ul>
		</nav>
    </header>
	</aside>

    <script>setLoadingBarProgress(40);</script>
    <div class="l_body">
    <div class='container clearfix'>
        <div class='l_main'>
            <article id="post" class="post white-box article-type-post" itemscope itemprop="blogPost">
  
<section class='meta'>
  
  
  <div class="meta" id="header-meta">
    
      
          <h1 class="title">THUMT代码详解（4）：infer阶段模型和数据流</h1>
      
    

    <div class='new-meta-box'>
      
        <div class='new-meta-item author'>
          <a href="https://zhanghuimeng.github.io">
            <i class="fas fa-user" aria-hidden="true"></i>
            张慕晖
          </a>
        </div>
      
      
        <div class="new-meta-item date">
          <a class='notlink'>
            <i class="fas fa-calendar-alt" aria-hidden="true"></i>
            2020-09-07
          </a>
        </div>
      
      
        
          
          <div class='new-meta-item category'>
            <a href='/categories/NLP/'>
              <i class="fas fa-folder-open" aria-hidden="true"></i>
              NLP
            </a>
          </div>
        
      
      
        
          <div class="new-meta-item browse busuanzi">
            <a class='notlink'>
              <i class="fas fa-eye" aria-hidden="true"></i>
              <span id="busuanzi_value_page_pv">
                <i class="fas fa-spinner fa-spin fa-fw" aria-hidden="true"></i>
              </span>
            </a>
          </div>
        
      
      
    </div>
    <hr>
  </div>
</section>

    <section class="article typo">
      <div class="article-entry" itemprop="articleBody">
        <p><a href="/post/thumt-code-summary-1">简介篇地址</a></p>
<a id="more"></a>
<p>本篇将分为两个部分：一部分讲evaluation部分的模型和数据流，另一部分讲inference部分的模型和数据流。两者本质上是差不多的。</p>
<h2>evaluation</h2>
<p>evaluation的入口处也在<a href="https://github.com/THUNLP-MT/THUMT/blob/pytorch/thumt/bin/trainer.py" target="_blank" rel="noopener">trainer.py</a>：</p>
<figure class="highlight py"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">if</span> step % params.eval_steps == <span class="number">0</span>:</span><br><span class="line">    utils.evaluate(model, sorted_key, eval_dataset,</span><br><span class="line">                    params.output, references, params)</span><br></pre></td></tr></table></figure>
<p>这里的<code>sorted_key</code>和<code>eval_dataset</code>和<code>references</code>就是<a href="/post/thumt-code-summary-2">THUMT代码详解（2）：数据处理</a>中提到的：</p>
<ul>
<li><code>sorted_key</code>：用于把排序过的数据复原</li>
<li><code>eval_dataset</code>：一个dataset，由<code>source</code>和<code>source_mask</code>组成</li>
<li><code>references</code>：分词后的target端的句子，用于计算bleu值</li>
</ul>
<p>然后就是<a href="https://github.com/THUNLP-MT/THUMT/blob/pytorch/thumt/utils/evaluation.py" target="_blank" rel="noopener">evaluation.py</a>：</p>
<figure class="highlight py"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br></pre></td><td class="code"><pre><span class="line"><span class="function"><span class="keyword">def</span> <span class="title">evaluate</span><span class="params">(model, sorted_key, dataset, base_dir, references, params)</span>:</span></span><br><span class="line">    <span class="keyword">if</span> <span class="keyword">not</span> references:</span><br><span class="line">        <span class="keyword">return</span></span><br><span class="line"></span><br><span class="line">    <span class="comment"># 各种文件的地址，目前没什么用</span></span><br><span class="line">    base_dir = base_dir.rstrip(<span class="string">"/"</span>)</span><br><span class="line">    save_path = os.path.join(base_dir, <span class="string">"eval"</span>)</span><br><span class="line">    record_name = os.path.join(save_path, <span class="string">"record"</span>)</span><br><span class="line">    log_name = os.path.join(save_path, <span class="string">"log"</span>)</span><br><span class="line">    max_to_keep = params.keep_top_checkpoint_max</span><br><span class="line"></span><br><span class="line">    <span class="comment"># 创建目录和文件，还是没什么用</span></span><br><span class="line">    <span class="keyword">if</span> dist.get_rank() == <span class="number">0</span>:</span><br><span class="line">        <span class="comment"># Create directory and copy files</span></span><br><span class="line">        <span class="keyword">if</span> <span class="keyword">not</span> os.path.exists(save_path):</span><br><span class="line">            print(<span class="string">"Making dir: %s"</span> % save_path)</span><br><span class="line">            os.makedirs(save_path)</span><br><span class="line"></span><br><span class="line">            params_pattern = os.path.join(base_dir, <span class="string">"*.json"</span>)</span><br><span class="line">            params_files = glob.glob(params_pattern)</span><br><span class="line"></span><br><span class="line">            <span class="keyword">for</span> name <span class="keyword">in</span> params_files:</span><br><span class="line">                new_name = name.replace(base_dir, save_path)</span><br><span class="line">                shutil.copy(name, new_name)</span><br><span class="line"></span><br><span class="line">    <span class="comment"># Do validation here</span></span><br><span class="line">    global_step = get_global_step()</span><br><span class="line"></span><br><span class="line">    <span class="keyword">if</span> dist.get_rank() == <span class="number">0</span>:</span><br><span class="line">        print(<span class="string">"Validating model at step %d"</span> % global_step)</span><br><span class="line"></span><br><span class="line">    <span class="comment"># 调用内部函数_evaluate_model，进行实际的evaluate工作</span></span><br><span class="line">    score = _evaluate_model(model, sorted_key, dataset, references, params)</span><br><span class="line">    .....</span><br></pre></td></tr></table></figure>
<p>调用<code>_evaluate_model</code>：</p>
<figure class="highlight py"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br></pre></td><td class="code"><pre><span class="line"><span class="function"><span class="keyword">def</span> <span class="title">_evaluate_model</span><span class="params">(model, sorted_key, dataset, references, params)</span>:</span></span><br><span class="line">    <span class="comment"># Create model</span></span><br><span class="line">    <span class="comment"># 在验证阶段不进行back-propagation</span></span><br><span class="line">    <span class="keyword">with</span> torch.no_grad():</span><br><span class="line">        <span class="comment"># 调整模型的模式</span></span><br><span class="line">        model.eval()</span><br><span class="line"></span><br><span class="line">        <span class="comment"># 得到dataset的iterator</span></span><br><span class="line">        iterator = iter(dataset)</span><br><span class="line">        counter = <span class="number">0</span></span><br><span class="line">        pad_max = <span class="number">1024</span></span><br><span class="line"></span><br><span class="line">        <span class="comment"># Buffers for synchronization</span></span><br><span class="line">        <span class="comment"># TODO</span></span><br><span class="line">        size = torch.zeros([dist.get_world_size()]).long()</span><br><span class="line">        t_list = [torch.empty([params.decode_batch_size, pad_max]).long()</span><br><span class="line">                  <span class="keyword">for</span> _ <span class="keyword">in</span> range(dist.get_world_size())]</span><br><span class="line">        results = []</span><br><span class="line"></span><br><span class="line">        <span class="keyword">while</span> <span class="keyword">True</span>:</span><br><span class="line">            <span class="keyword">try</span>:</span><br><span class="line">                features = next(iterator)</span><br><span class="line">                <span class="comment"># 这部分中继续对features进行处理，这个函数之前也见过了，就是把string转换成id</span></span><br><span class="line">                <span class="comment"># 所以就不细讲了</span></span><br><span class="line">                features = lookup(features, <span class="string">"infer"</span>, params)</span><br><span class="line">                batch_size = features[<span class="string">"source"</span>].shape[<span class="number">0</span>]</span><br><span class="line">            <span class="keyword">except</span>:</span><br><span class="line">                features = &#123;</span><br><span class="line">                    <span class="string">"source"</span>: torch.ones([<span class="number">1</span>, <span class="number">1</span>]).long(),</span><br><span class="line">                    <span class="string">"source_mask"</span>: torch.ones([<span class="number">1</span>, <span class="number">1</span>]).float()</span><br><span class="line">                &#125;</span><br><span class="line">                batch_size = <span class="number">0</span></span><br><span class="line"></span><br><span class="line">            t = time.time()</span><br><span class="line">            counter += <span class="number">1</span></span><br><span class="line"></span><br><span class="line">            <span class="comment"># Decode</span></span><br><span class="line">            <span class="comment"># 调用beam_search进行实际解码工作</span></span><br><span class="line">            seqs, _ = beam_search([model], features, params)</span><br><span class="line">            ......</span><br></pre></td></tr></table></figure>
<p><code>beam_search</code>位于<a href="https://github.com/THUNLP-MT/THUMT/blob/pytorch/thumt/utils/inference.py" target="_blank" rel="noopener">inference.py</a>：</p>
<figure class="highlight py"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br><span class="line">44</span><br><span class="line">45</span><br><span class="line">46</span><br><span class="line">47</span><br><span class="line">48</span><br><span class="line">49</span><br><span class="line">50</span><br><span class="line">51</span><br><span class="line">52</span><br><span class="line">53</span><br><span class="line">54</span><br><span class="line">55</span><br><span class="line">56</span><br><span class="line">57</span><br><span class="line">58</span><br><span class="line">59</span><br></pre></td><td class="code"><pre><span class="line"><span class="function"><span class="keyword">def</span> <span class="title">beam_search</span><span class="params">(models, features, params)</span>:</span></span><br><span class="line">    <span class="keyword">if</span> <span class="keyword">not</span> isinstance(models, (list, tuple)):</span><br><span class="line">        <span class="keyword">raise</span> ValueError(<span class="string">"'models' must be a list or tuple"</span>)</span><br><span class="line"></span><br><span class="line">    beam_size = params.beam_size</span><br><span class="line">    top_beams = params.top_beams</span><br><span class="line">    alpha = params.decode_alpha</span><br><span class="line">    decode_ratio = params.decode_ratio</span><br><span class="line">    decode_length = params.decode_length</span><br><span class="line"></span><br><span class="line">    pad_id = params.lookup[<span class="string">"target"</span>][params.pad.encode(<span class="string">"utf-8"</span>)]</span><br><span class="line">    bos_id = params.lookup[<span class="string">"target"</span>][params.bos.encode(<span class="string">"utf-8"</span>)]</span><br><span class="line">    eos_id = params.lookup[<span class="string">"target"</span>][params.eos.encode(<span class="string">"utf-8"</span>)]</span><br><span class="line"></span><br><span class="line">    min_val = <span class="number">-1e9</span></span><br><span class="line">    shape = features[<span class="string">"source"</span>].shape</span><br><span class="line">    device = features[<span class="string">"source"</span>].device</span><br><span class="line">    batch_size = shape[<span class="number">0</span>]</span><br><span class="line">    seq_length = shape[<span class="number">1</span>]</span><br><span class="line"></span><br><span class="line">    <span class="comment"># Compute initial state if necessary</span></span><br><span class="line">    states = []</span><br><span class="line">    funcs = []</span><br><span class="line"></span><br><span class="line">    <span class="comment"># 对每个model，都计算出encode之后的state：</span></span><br><span class="line">    <span class="comment"># &#123;</span></span><br><span class="line">    <span class="comment">#     "encoder_output": [batch, length_s, hidden],</span></span><br><span class="line">    <span class="comment">#     "enc_attn_bias": [batch, 1, 1, length_s],</span></span><br><span class="line">    <span class="comment">#     "decoder": ...</span></span><br><span class="line">    <span class="comment"># &#125;</span></span><br><span class="line">    <span class="comment"># encode函数之前已经讲了很多了，这里和训练阶段没有区别，所以就不讲了==</span></span><br><span class="line">    <span class="keyword">for</span> model <span class="keyword">in</span> models:</span><br><span class="line">        state = model.empty_state(batch_size, device)</span><br><span class="line">        states.append(model.encode(features, state))</span><br><span class="line">        funcs.append(model.decode)</span><br><span class="line"></span><br><span class="line">    <span class="comment"># For source sequence length</span></span><br><span class="line">    <span class="comment"># 计算每个句子译码时的最长长度</span></span><br><span class="line">    max_length = features[<span class="string">"source_mask"</span>].sum(<span class="number">1</span>) * decode_ratio</span><br><span class="line">    max_length = max_length.long() + decode_length</span><br><span class="line">    max_step = max_length.max()</span><br><span class="line">    <span class="comment"># [batch, beam_size]</span></span><br><span class="line">    <span class="comment"># 把长度扩展beam_size倍</span></span><br><span class="line">    max_length = torch.unsqueeze(max_length, <span class="number">1</span>).repeat([<span class="number">1</span>, beam_size])</span><br><span class="line"></span><br><span class="line">    <span class="comment"># Expand the inputs</span></span><br><span class="line">    <span class="comment"># [batch, length] =&gt; [batch * beam_size, length]</span></span><br><span class="line">    <span class="comment"># [batch, 1, length]</span></span><br><span class="line">    features[<span class="string">"source"</span>] = torch.unsqueeze(features[<span class="string">"source"</span>], <span class="number">1</span>)</span><br><span class="line">    <span class="comment"># [batch, beam_size, length]</span></span><br><span class="line">    features[<span class="string">"source"</span>] = features[<span class="string">"source"</span>].repeat([<span class="number">1</span>, beam_size, <span class="number">1</span>])</span><br><span class="line">    <span class="comment"># [batch * beam_size, length]</span></span><br><span class="line">    features[<span class="string">"source"</span>] = torch.reshape(features[<span class="string">"source"</span>],</span><br><span class="line">                                       [batch_size * beam_size, seq_length])</span><br><span class="line">    features[<span class="string">"source_mask"</span>] = torch.unsqueeze(features[<span class="string">"source_mask"</span>], <span class="number">1</span>)</span><br><span class="line">    features[<span class="string">"source_mask"</span>] = features[<span class="string">"source_mask"</span>].repeat([<span class="number">1</span>, beam_size, <span class="number">1</span>])</span><br><span class="line">    features[<span class="string">"source_mask"</span>] = torch.reshape(features[<span class="string">"source_mask"</span>],</span><br><span class="line">                                       [batch_size * beam_size, seq_length])</span><br><span class="line">    ......</span><br></pre></td></tr></table></figure>
<p>这里使用了大量的<a href="https://pytorch.org/docs/stable/tensors.html#torch.Tensor.repeat" target="_blank" rel="noopener">torch.repeat</a>函数，其主要目的代码里已经写得很清楚了，就是把每个句子扩展<code>beam_size</code>倍，用于在beam search中使用。唯一值得注意的是，这里是整体重复而不是interleave的。</p>
<figure class="highlight py"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br><span class="line">44</span><br><span class="line">45</span><br><span class="line">46</span><br><span class="line">47</span><br><span class="line">48</span><br><span class="line">49</span><br><span class="line">50</span><br><span class="line">51</span><br><span class="line">52</span><br><span class="line">53</span><br><span class="line">54</span><br><span class="line">55</span><br><span class="line">56</span><br><span class="line">57</span><br><span class="line">58</span><br><span class="line">59</span><br><span class="line">60</span><br><span class="line">61</span><br><span class="line">62</span><br></pre></td><td class="code"><pre><span class="line"><span class="function"><span class="keyword">def</span> <span class="title">beam_search</span><span class="params">(models, features, params)</span>:</span></span><br><span class="line">    ......</span><br><span class="line">    <span class="comment"># 把decode函数和features传过去了</span></span><br><span class="line">    <span class="comment"># 等到用到的时候再说</span></span><br><span class="line">    decoding_fn = _get_inference_fn(funcs, features)</span><br><span class="line"></span><br><span class="line">    <span class="comment"># 把每个states里的每个tensor都重复beam遍（增加第二维）</span></span><br><span class="line">    <span class="comment"># 主要作用在encoder_output和enc_attn_bias上</span></span><br><span class="line">    <span class="comment"># 因为感觉和主体内容没什么关系所以不讲了</span></span><br><span class="line">    <span class="comment"># 感兴趣的话请自行阅读nest.py</span></span><br><span class="line">    <span class="comment"># states[0]["encoder_output"]: [batch, beam, length_s, hidden]</span></span><br><span class="line">    <span class="comment"># states[0]["enc_attn_bias"]: [batch, beam, 1, 1, length_s]</span></span><br><span class="line">    states = map_structure(</span><br><span class="line">        <span class="keyword">lambda</span> x: _tile_to_beam_size(x, beam_size),</span><br><span class="line">        states)</span><br><span class="line"></span><br><span class="line">    <span class="comment"># Initial beam search state</span></span><br><span class="line">    <span class="comment"># 创建一个维度是[batch_size, beam_size, 1]的矩阵，填充上&lt;bos&gt;</span></span><br><span class="line">    <span class="comment"># 用途是 TODO</span></span><br><span class="line">    init_seqs = torch.full([batch_size, beam_size, <span class="number">1</span>], bos_id, device=device)</span><br><span class="line">    init_seqs = init_seqs.long()</span><br><span class="line">    <span class="comment"># 创建一个维度是[batch_size, beam_size]的矩阵，第一列是0，其他列是无穷小</span></span><br><span class="line">    <span class="comment"># 用途是 TODO</span></span><br><span class="line">    init_log_probs = init_seqs.new_tensor(</span><br><span class="line">        [[<span class="number">0.</span>] + [min_val] * (beam_size - <span class="number">1</span>)], dtype=torch.float32)</span><br><span class="line">    init_log_probs = init_log_probs.repeat([batch_size, <span class="number">1</span>])</span><br><span class="line">    <span class="comment"># 创建一个维度是[batch_size, beam_size]的矩阵，全部为0</span></span><br><span class="line">    <span class="comment"># 用途是 TODO</span></span><br><span class="line">    <span class="comment"># score和log_probs的区别似乎是，score有一个length penalty</span></span><br><span class="line">    init_scores = torch.zeros_like(init_log_probs)</span><br><span class="line">    <span class="comment"># 创建结束状态矩阵</span></span><br><span class="line">    <span class="comment"># 为每个句子维护beam_size个分最高的已完成的句子</span></span><br><span class="line">    <span class="comment"># 用途是 TODO （我猜，inputs是未完成的句子，finish是已完成的句子）</span></span><br><span class="line">    fin_seqs = torch.zeros([batch_size, beam_size, <span class="number">1</span>], dtype=torch.int64,</span><br><span class="line">                           device=device)</span><br><span class="line">    fin_scores = torch.full([batch_size, beam_size], min_val,</span><br><span class="line">                            dtype=torch.float32, device=device)</span><br><span class="line">    fin_flags = torch.zeros([batch_size, beam_size], dtype=torch.bool,</span><br><span class="line">                            device=device)</span><br><span class="line"></span><br><span class="line">    <span class="comment"># 创建BeamSearchState，把刚才的状态矩阵都放进去</span></span><br><span class="line">    <span class="comment"># 以及state TODO</span></span><br><span class="line">    state = BeamSearchState(</span><br><span class="line">        inputs=(init_seqs, init_log_probs, init_scores),</span><br><span class="line">        state=states,</span><br><span class="line">        finish=(fin_flags, fin_seqs, fin_scores),</span><br><span class="line">    )</span><br><span class="line"></span><br><span class="line">    <span class="comment"># 接下来进入beam search每个step的循环</span></span><br><span class="line">    <span class="comment"># 循环结束的条件是，尚未结束的beam的最高可能得分低于目前已有的最低得分</span></span><br><span class="line">    <span class="keyword">for</span> time <span class="keyword">in</span> range(max_step):</span><br><span class="line">        state = _beam_search_step(time, decoding_fn, state, batch_size,</span><br><span class="line">                                  beam_size, alpha, pad_id, eos_id, max_length)</span><br><span class="line">        max_penalty = ((<span class="number">5.0</span> + max_step) / <span class="number">6.0</span>) ** alpha</span><br><span class="line">        best_alive_score = torch.max(state.inputs[<span class="number">1</span>][:, <span class="number">0</span>] / max_penalty)</span><br><span class="line">        worst_finished_score = torch.min(state.finish[<span class="number">2</span>])</span><br><span class="line">        cond = torch.gt(worst_finished_score, best_alive_score)</span><br><span class="line">        is_finished = bool(cond)</span><br><span class="line"></span><br><span class="line">        <span class="keyword">if</span> is_finished:</span><br><span class="line">            <span class="keyword">break</span></span><br><span class="line">    ......</span><br></pre></td></tr></table></figure>
<p>然后我们来看<code>_beam_search_step</code>这个函数：</p>
<figure class="highlight py"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment"># time：当前时间步</span></span><br><span class="line"><span class="comment"># func：用于解码的函数，实际上就是Transformer.decode</span></span><br><span class="line"><span class="comment"># state：包括inputs、state和finish三个属性</span></span><br><span class="line"><span class="comment"># ......</span></span><br><span class="line"><span class="function"><span class="keyword">def</span> <span class="title">_beam_search_step</span><span class="params">(time, func, state, batch_size, beam_size, alpha,</span></span></span><br><span class="line"><span class="function"><span class="params">                      pad_id, eos_id, max_length, inf=<span class="number">-1e9</span>)</span>:</span></span><br><span class="line">    <span class="comment"># Compute log probabilities</span></span><br><span class="line">    <span class="comment"># seqs: [batch, beam, time + 1]</span></span><br><span class="line">    <span class="comment"># log_probs: [batch, beam]</span></span><br><span class="line">    seqs, log_probs = state.inputs[:<span class="number">2</span>]</span><br><span class="line">    <span class="comment"># 合并前两维</span></span><br><span class="line">    <span class="comment"># flat_seqs: [batch * beam, time + 1]</span></span><br><span class="line">    flat_seqs = _merge_first_two_dims(seqs)</span><br><span class="line">    <span class="comment"># flat_state[0]["encoder_output"]: [batch * beam, length_s, hidden]</span></span><br><span class="line">    <span class="comment"># flat_state[0]["enc_attn_bias"]: [batch * beam, 1, 1, length_s]</span></span><br><span class="line">    <span class="comment"># flat_state[0]["decoder"]["layer_0"]["k"]: [batch * beam, time, hidden]</span></span><br><span class="line">    flat_state = map_structure(<span class="keyword">lambda</span> x: _merge_first_two_dims(x), state.state)</span><br><span class="line">    step_log_probs, next_state = func(flat_seqs, flat_state)</span><br><span class="line">    ......</span><br></pre></td></tr></table></figure>
<p>这时再把<code>_get_inference_fn</code>拿出来看看：</p>
<figure class="highlight py"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br></pre></td><td class="code"><pre><span class="line"><span class="function"><span class="keyword">def</span> <span class="title">_get_inference_fn</span><span class="params">(model_fns, features)</span>:</span></span><br><span class="line">    <span class="function"><span class="keyword">def</span> <span class="title">inference_fn</span><span class="params">(inputs, state)</span>:</span></span><br><span class="line">        <span class="comment"># 这里的features是beam_search里已经按beam重复过的source和source_mask</span></span><br><span class="line">        <span class="comment"># target显然是beam search中已经decode出的sequence</span></span><br><span class="line">        <span class="comment"># target_mask全1（因为这个mask只在Transformer.forward中计算loss时有用）</span></span><br><span class="line">        <span class="comment"># target, target_mask: [batch * beam, time + 1]</span></span><br><span class="line">        local_features = &#123;</span><br><span class="line">            <span class="string">"source"</span>: features[<span class="string">"source"</span>],</span><br><span class="line">            <span class="string">"source_mask"</span>: features[<span class="string">"source_mask"</span>],</span><br><span class="line">            <span class="string">"target"</span>: inputs,</span><br><span class="line">            <span class="string">"target_mask"</span>: torch.ones(*inputs.shape).float().cuda()</span><br><span class="line">        &#125;</span><br><span class="line"></span><br><span class="line">        outputs = []</span><br><span class="line">        next_state = []</span><br><span class="line"></span><br><span class="line">        <span class="keyword">for</span> (model_fn, model_state) <span class="keyword">in</span> zip(model_fns, state):</span><br><span class="line">            <span class="comment"># 把state输入给Transformer.decode，得到logits和新的state</span></span><br><span class="line">            <span class="comment"># state["encoder_output"]: [batch * beam, length_s, hidden]</span></span><br><span class="line">            <span class="comment"># state["enc_attn_bias"]: [batch * beam, 1, 1, length_s]</span></span><br><span class="line">            <span class="comment"># state["decoder"]["layer_0"]["k"]: [batch * beam, time, hidden]</span></span><br><span class="line">            <span class="keyword">if</span> model_state:</span><br><span class="line">                <span class="comment"># logits: [batch * beam, tvoc_size]</span></span><br><span class="line">                <span class="comment"># new_state["encoder_output"]: [batch * beam, length_s, hidden]（不变）</span></span><br><span class="line">                <span class="comment"># new_state["enc_attn_bias"]: [batch * beam, 1, 1, length_s]（不变）</span></span><br><span class="line">                <span class="comment"># new_state["decoder"]["layer_0"]["k"]: [batch * beam, time + 1, hidden]</span></span><br><span class="line">                logits, new_state = model_fn(local_features, model_state)</span><br><span class="line">                ......</span><br></pre></td></tr></table></figure>
<p>这里调用的<code>Transformer.decode</code>和训练阶段的是有一些区别的。简单来说，就是attention的key只留下了当前的一个token，而query和value用的是整个句子。这是因为infer阶段只需要在一个位置上进行预测。因为这部分太多了（如果细讲，还是需要把decoder再过一遍），所以这部分放到附录中。</p>
<p>TODO （描述可能不够清晰）</p>
<figure class="highlight py"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br></pre></td><td class="code"><pre><span class="line"><span class="function"><span class="keyword">def</span> <span class="title">_get_inference_fn</span><span class="params">(model_fns, features)</span>:</span></span><br><span class="line">    <span class="function"><span class="keyword">def</span> <span class="title">inference_fn</span><span class="params">(inputs, state)</span>:</span></span><br><span class="line">                ......</span><br><span class="line">                <span class="comment"># 对最后一维做softmax，然后做log，得到log_prob</span></span><br><span class="line">                <span class="comment"># outputs: [batch * beam, tvoc_size]</span></span><br><span class="line">                outputs.append(torch.nn.functional.log_softmax(logits,</span><br><span class="line">                                                               dim=<span class="number">-1</span>))</span><br><span class="line">                next_state.append(new_state)</span><br><span class="line">            <span class="keyword">else</span>:</span><br><span class="line">                logits = model_fn(local_features)</span><br><span class="line">                outputs.append(torch.nn.functional.log_softmax(logits,</span><br><span class="line">                                                               dim=<span class="number">-1</span>))</span><br><span class="line">                next_state.append(&#123;&#125;)</span><br><span class="line"></span><br><span class="line">        <span class="comment"># Ensemble</span></span><br><span class="line">        <span class="comment"># 对所有模型输出的log_prob取个平均值</span></span><br><span class="line">        <span class="comment"># log_prob: [batch * beam, tvoc_size]</span></span><br><span class="line">        log_prob = sum(outputs) / float(len(outputs))</span><br><span class="line"></span><br><span class="line">        <span class="keyword">return</span> log_prob.float(), next_state</span><br><span class="line"></span><br><span class="line">    <span class="keyword">return</span> inference_fn</span><br></pre></td></tr></table></figure>
<p>在decode完之后，回到<code>_beam_search_step</code>，进行下一步的处理：</p>
<figure class="highlight py"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br><span class="line">44</span><br></pre></td><td class="code"><pre><span class="line"><span class="function"><span class="keyword">def</span> <span class="title">_beam_search_step</span><span class="params">(time, func, state, batch_size, beam_size, alpha,</span></span></span><br><span class="line"><span class="function"><span class="params">                      pad_id, eos_id, max_length, inf=<span class="number">-1e9</span>)</span>:</span></span><br><span class="line">    ......</span><br><span class="line">    <span class="comment"># step_log_probs: [batch, beam, tvoc_size]</span></span><br><span class="line">    step_log_probs = _split_first_two_dims(step_log_probs, batch_size,</span><br><span class="line">                                           beam_size)</span><br><span class="line">    <span class="comment"># 把state中的tensor的前两维展开（虽然下一次计算之前又会折叠回去）</span></span><br><span class="line">    <span class="comment"># next_state[0]["encoder_output"]: [batch, beam, length_s, hidden]</span></span><br><span class="line">    <span class="comment"># next_state[0]["enc_attn_bias"]: [batch, beam, 1, 1, length_s]</span></span><br><span class="line">    <span class="comment"># next_state[0]["decoder"]["layer_0"]["k"]: [batch, beam, time + 1, hidden]</span></span><br><span class="line">    next_state = map_structure(</span><br><span class="line">        <span class="keyword">lambda</span> x: _split_first_two_dims(x, batch_size, beam_size), next_state)</span><br><span class="line">    <span class="comment"># 加法broadcast，维度[batch, beam, 1] + 维度[batch, beam, tvoc_size]</span></span><br><span class="line">    <span class="comment"># 结果维度为[batch, beam, tvoc_size]，相当于每个batch的每个beam在每个词上继续延伸都有一个概率</span></span><br><span class="line">    curr_log_probs = torch.unsqueeze(log_probs, <span class="number">2</span>) + step_log_probs</span><br><span class="line"></span><br><span class="line">    <span class="comment"># Apply length penalty</span></span><br><span class="line">    <span class="comment"># 当前decode出的sequence长度是time+1，batch内的所有sequence长度都是一样的</span></span><br><span class="line">    <span class="comment"># （除了那些已经结束的，但是反正不用管）</span></span><br><span class="line">    <span class="comment"># TODO</span></span><br><span class="line">    <span class="comment"># 对log prob施加长度惩罚，得到scores</span></span><br><span class="line">    length_penalty = ((<span class="number">5.0</span> + float(time + <span class="number">1</span>)) / <span class="number">6.0</span>) ** alpha</span><br><span class="line">    <span class="comment"># curr_scores: [batch, beam, tvoc_size]</span></span><br><span class="line">    curr_scores = curr_log_probs / length_penalty</span><br><span class="line">    <span class="comment"># vocab_size = tvoc_size</span></span><br><span class="line">    vocab_size = curr_scores.shape[<span class="number">-1</span>]</span><br><span class="line"></span><br><span class="line">    <span class="comment"># Select top-k candidates</span></span><br><span class="line">    <span class="comment"># 从每个句子的所有beam的每个可能的下一个词（共beam*vocab个）中找出最好的2*beam个</span></span><br><span class="line">    <span class="comment"># 作为下一轮beam的候选</span></span><br><span class="line">    <span class="comment"># TODO：为什么是2*beam个？</span></span><br><span class="line">    <span class="comment"># [batch_size, beam_size * vocab_size]</span></span><br><span class="line">    curr_scores = torch.reshape(curr_scores, [<span class="number">-1</span>, beam_size * vocab_size])</span><br><span class="line">    <span class="comment"># [batch_size, 2 * beam_size]</span></span><br><span class="line">    top_scores, top_indices = torch.topk(curr_scores, k=<span class="number">2</span>*beam_size)</span><br><span class="line">    <span class="comment"># Shape: [batch_size, 2 * beam_size]</span></span><br><span class="line">    <span class="comment"># 新的beam是从哪一个beam延伸出来的</span></span><br><span class="line">    beam_indices = top_indices // vocab_size</span><br><span class="line">    <span class="comment"># 新的beam对应的具体是哪个词</span></span><br><span class="line">    symbol_indices = top_indices % vocab_size</span><br><span class="line">    <span class="comment"># Expand sequences</span></span><br><span class="line">    <span class="comment"># [batch_size, 2 * beam_size, time + 1]</span></span><br><span class="line">    candidate_seqs = _gather_2d(seqs, beam_indices)</span><br><span class="line">    ......</span><br></pre></td></tr></table></figure>
<p>这里的<code>_gather_2d</code>函数的功能可能不太好理解。<a href="https://pytorch.org/docs/stable/generated/torch.gather.html" target="_blank" rel="noopener">torch.gather</a>这个函数的本意是从tensor中挑出一些组合在一起；在这里就是根据<code>beam_indices</code>挑出一些beam然后组合在一起。</p>
<figure class="highlight py"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment"># params: [batch, beam, time + 1]</span></span><br><span class="line"><span class="comment"># indices: [batch, 2 * beam]</span></span><br><span class="line"><span class="function"><span class="keyword">def</span> <span class="title">_gather_2d</span><span class="params">(params, indices, name=None)</span>:</span></span><br><span class="line">    batch_size = params.shape[<span class="number">0</span>]</span><br><span class="line">    <span class="comment"># range_size = 2 * beam</span></span><br><span class="line">    range_size = indices.shape[<span class="number">1</span>]</span><br><span class="line">    <span class="comment"># 返回一个长度为2 * batch * beam的tensor，内容是[0, 1, ......, 2 * batch * beam - 1]</span></span><br><span class="line">    batch_pos = torch.arange(batch_size * range_size, device=params.device)</span><br><span class="line">    <span class="comment"># batch_pos = [0, 0, ... 0, 1, 1, ..., 1, ..., batch - 1, batch - 1, ..., batch - 1]</span></span><br><span class="line">    <span class="comment"># 每种数字出现的次数是2 * beam次</span></span><br><span class="line">    batch_pos = batch_pos // range_size</span><br><span class="line">    <span class="comment"># batch_pos: [batch, 2 * beam]</span></span><br><span class="line">    <span class="comment"># batch_pos = [[0, 0, ..., 0], [1, 1, ..., 1], ..., [batch - 1, batch - 1, ..., batch - 1]]</span></span><br><span class="line">    batch_pos = torch.reshape(batch_pos, [batch_size, range_size])</span><br><span class="line">    <span class="comment"># TODO：这里实在想象不出来了。。。</span></span><br><span class="line">    output = params[batch_pos, indices]</span><br><span class="line"></span><br><span class="line">    <span class="keyword">return</span> output</span><br></pre></td></tr></table></figure>
<p>再次回到<code>_beam_search_step</code>：</p>
<figure class="highlight py"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br><span class="line">44</span><br><span class="line">45</span><br><span class="line">46</span><br><span class="line">47</span><br><span class="line">48</span><br><span class="line">49</span><br><span class="line">50</span><br><span class="line">51</span><br><span class="line">52</span><br><span class="line">53</span><br><span class="line">54</span><br><span class="line">55</span><br><span class="line">56</span><br><span class="line">57</span><br><span class="line">58</span><br><span class="line">59</span><br><span class="line">60</span><br><span class="line">61</span><br><span class="line">62</span><br><span class="line">63</span><br><span class="line">64</span><br><span class="line">65</span><br><span class="line">66</span><br><span class="line">67</span><br><span class="line">68</span><br></pre></td><td class="code"><pre><span class="line"><span class="function"><span class="keyword">def</span> <span class="title">_beam_search_step</span><span class="params">(time, func, state, batch_size, beam_size, alpha,</span></span></span><br><span class="line"><span class="function"><span class="params">                      pad_id, eos_id, max_length, inf=<span class="number">-1e9</span>)</span>:</span></span><br><span class="line">    ......</span><br><span class="line">    <span class="comment"># 接下来把词连上去</span></span><br><span class="line">    <span class="comment"># candidate_seqs: [batch, 2 * beam, time + 2]</span></span><br><span class="line">    candidate_seqs = torch.cat([candidate_seqs,</span><br><span class="line">                                torch.unsqueeze(symbol_indices, <span class="number">2</span>)], <span class="number">2</span>)</span><br><span class="line"></span><br><span class="line">    <span class="comment"># Expand sequences</span></span><br><span class="line">    <span class="comment"># Suppress finished sequences</span></span><br><span class="line">    <span class="comment"># 找出那些产生了&lt;eos&gt;的句子</span></span><br><span class="line">    flags = torch.eq(symbol_indices, eos_id).to(torch.bool)</span><br><span class="line">    <span class="comment"># 将已经结束的句子的分数置为无穷小</span></span><br><span class="line">    <span class="comment"># [batch, 2 * beam_size]</span></span><br><span class="line">    alive_scores = top_scores + flags.to(torch.float32) * inf</span><br><span class="line">    <span class="comment"># 在每个句子中挑出beam个分数最高的句子</span></span><br><span class="line">    <span class="comment"># [batch, beam_size]</span></span><br><span class="line">    alive_scores, alive_indices = torch.topk(alive_scores, beam_size)</span><br><span class="line">    <span class="comment"># 找出对应的词</span></span><br><span class="line">    <span class="comment"># TODO</span></span><br><span class="line">    <span class="comment"># alive_symbols: [batch, beam]</span></span><br><span class="line">    alive_symbols = _gather_2d(symbol_indices, alive_indices)</span><br><span class="line">    <span class="comment"># 找出对应的beam位置</span></span><br><span class="line">    <span class="comment"># TODO</span></span><br><span class="line">    <span class="comment"># alive_indices: [batch, beam]</span></span><br><span class="line">    alive_indices = _gather_2d(beam_indices, alive_indices)</span><br><span class="line">    <span class="comment"># 找出对应的sequence</span></span><br><span class="line">    <span class="comment"># TODO</span></span><br><span class="line">    <span class="comment"># alive_seqs: [batch, beam, time + 1]</span></span><br><span class="line">    alive_seqs = _gather_2d(seqs, alive_indices)</span><br><span class="line">    <span class="comment"># 把新的词连接上去</span></span><br><span class="line">    <span class="comment"># alive_seqs: [batch_size, beam_size, time + 2]</span></span><br><span class="line">    alive_seqs = torch.cat([alive_seqs, torch.unsqueeze(alive_symbols, <span class="number">2</span>)], <span class="number">2</span>)</span><br><span class="line">    <span class="comment"># alive_state[0]["encoder_output"]: [batch, beam, length_s, hidden]</span></span><br><span class="line">    <span class="comment"># alive_state[0]["enc_attn_bias"]: [batch, beam, 1, 1, length_s]</span></span><br><span class="line">    <span class="comment"># alive_state[0]["decoder"]["layer_0"]["k"]: [batch, beam, time + 1, hidden]</span></span><br><span class="line">    alive_state = map_structure(</span><br><span class="line">        <span class="keyword">lambda</span> x: _gather_2d(x, alive_indices),</span><br><span class="line">        next_state)</span><br><span class="line">    alive_log_probs = alive_scores * length_penalty</span><br><span class="line">    <span class="comment"># Check length constraint</span></span><br><span class="line">    <span class="comment"># 如果句子长度超过限制，则分数设为无穷小</span></span><br><span class="line">    length_flags = torch.le(max_length, time + <span class="number">1</span>).float()</span><br><span class="line">    alive_log_probs = alive_log_probs + length_flags * inf</span><br><span class="line">    alive_scores = alive_scores + length_flags * inf</span><br><span class="line"></span><br><span class="line">    <span class="comment"># Select finished sequences</span></span><br><span class="line">    prev_fin_flags, prev_fin_seqs, prev_fin_scores = state.finish</span><br><span class="line">    <span class="comment"># [batch, 2 * beam_size]</span></span><br><span class="line">    step_fin_scores = top_scores + (<span class="number">1.0</span> - flags.to(torch.float32)) * inf</span><br><span class="line">    <span class="comment"># [batch, 3 * beam_size]</span></span><br><span class="line">    fin_flags = torch.cat([prev_fin_flags, flags], dim=<span class="number">1</span>)</span><br><span class="line">    fin_scores = torch.cat([prev_fin_scores, step_fin_scores], dim=<span class="number">1</span>)</span><br><span class="line">    <span class="comment"># [batch, beam_size]</span></span><br><span class="line">    fin_scores, fin_indices = torch.topk(fin_scores, beam_size)</span><br><span class="line">    fin_flags = _gather_2d(fin_flags, fin_indices)</span><br><span class="line">    pad_seqs = prev_fin_seqs.new_full([batch_size, beam_size, <span class="number">1</span>], pad_id)</span><br><span class="line">    prev_fin_seqs = torch.cat([prev_fin_seqs, pad_seqs], dim=<span class="number">2</span>)</span><br><span class="line">    fin_seqs = torch.cat([prev_fin_seqs, candidate_seqs], dim=<span class="number">1</span>)</span><br><span class="line">    fin_seqs = _gather_2d(fin_seqs, fin_indices)</span><br><span class="line"></span><br><span class="line">    new_state = BeamSearchState(</span><br><span class="line">        inputs=(alive_seqs, alive_log_probs, alive_scores),</span><br><span class="line">        state=alive_state,</span><br><span class="line">        finish=(fin_flags, fin_seqs, fin_scores),</span><br><span class="line">    )</span><br><span class="line"></span><br><span class="line">    <span class="keyword">return</span> new_state</span><br></pre></td></tr></table></figure>
<figure class="highlight py"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br></pre></td><td class="code"><pre><span class="line"><span class="function"><span class="keyword">def</span> <span class="title">beam_search</span><span class="params">(models, features, params)</span>:</span></span><br><span class="line">    ......</span><br><span class="line">    final_state = state</span><br><span class="line">    alive_seqs = final_state.inputs[<span class="number">0</span>]</span><br><span class="line">    alive_scores = final_state.inputs[<span class="number">2</span>]</span><br><span class="line">    final_flags = final_state.finish[<span class="number">0</span>].byte()</span><br><span class="line">    final_seqs = final_state.finish[<span class="number">1</span>]</span><br><span class="line">    final_scores = final_state.finish[<span class="number">2</span>]</span><br><span class="line"></span><br><span class="line">    final_seqs = torch.where(final_flags[:, :, <span class="keyword">None</span>], final_seqs, alive_seqs)</span><br><span class="line">    final_scores = torch.where(final_flags, final_scores, alive_scores)</span><br><span class="line"></span><br><span class="line">    <span class="comment"># Append extra &lt;eos&gt;</span></span><br><span class="line">    final_seqs = torch.nn.functional.pad(final_seqs, (<span class="number">0</span>, <span class="number">1</span>, <span class="number">0</span>, <span class="number">0</span>, <span class="number">0</span>, <span class="number">0</span>),</span><br><span class="line">                                         value=eos_id)</span><br><span class="line"></span><br><span class="line">    <span class="keyword">return</span> final_seqs[:, :top_beams, <span class="number">1</span>:], final_scores[:, :top_beams]</span><br></pre></td></tr></table></figure>
<p>然后再回到<code>_evaluate_model</code>：</p>
<figure class="highlight py"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br><span class="line">44</span><br><span class="line">45</span><br><span class="line">46</span><br><span class="line">47</span><br></pre></td><td class="code"><pre><span class="line"><span class="function"><span class="keyword">def</span> <span class="title">_evaluate_model</span><span class="params">(model, sorted_key, dataset, references, params)</span>:</span></span><br><span class="line">            ......</span><br><span class="line">            <span class="comment"># Padding</span></span><br><span class="line">            seqs = torch.squeeze(seqs, dim=<span class="number">1</span>)</span><br><span class="line">            pad_batch = params.decode_batch_size - seqs.shape[<span class="number">0</span>]</span><br><span class="line">            pad_length = pad_max - seqs.shape[<span class="number">1</span>]</span><br><span class="line">            seqs = torch.nn.functional.pad(seqs, (<span class="number">0</span>, pad_length, <span class="number">0</span>, pad_batch))</span><br><span class="line"></span><br><span class="line">            <span class="comment"># Synchronization</span></span><br><span class="line">            size.zero_()</span><br><span class="line">            size[dist.get_rank()].copy_(torch.tensor(batch_size))</span><br><span class="line">            dist.all_reduce(size)</span><br><span class="line">            dist.all_gather(t_list, seqs)</span><br><span class="line"></span><br><span class="line">            <span class="keyword">if</span> size.sum() == <span class="number">0</span>:</span><br><span class="line">                <span class="keyword">break</span></span><br><span class="line"></span><br><span class="line">            <span class="keyword">if</span> dist.get_rank() != <span class="number">0</span>:</span><br><span class="line">                <span class="keyword">continue</span></span><br><span class="line"></span><br><span class="line">            <span class="keyword">for</span> i <span class="keyword">in</span> range(params.decode_batch_size):</span><br><span class="line">                <span class="keyword">for</span> j <span class="keyword">in</span> range(dist.get_world_size()):</span><br><span class="line">                    n = size[j]</span><br><span class="line">                    seq = _convert_to_string(t_list[j][i], params)</span><br><span class="line"></span><br><span class="line">                    <span class="keyword">if</span> i &gt;= n:</span><br><span class="line">                        <span class="keyword">continue</span></span><br><span class="line"></span><br><span class="line">                    <span class="comment"># Restore BPE segmentation</span></span><br><span class="line">                    seq = BPE.decode(seq)</span><br><span class="line"></span><br><span class="line">                    results.append(seq.split())</span><br><span class="line"></span><br><span class="line">            t = time.time() - t</span><br><span class="line">            print(<span class="string">"Finished batch: %d (%.3f sec)"</span> % (counter, t))</span><br><span class="line"></span><br><span class="line">    model.train()</span><br><span class="line"></span><br><span class="line">    <span class="keyword">if</span> dist.get_rank() == <span class="number">0</span>:</span><br><span class="line">        restored_results = []</span><br><span class="line"></span><br><span class="line">        <span class="keyword">for</span> idx <span class="keyword">in</span> range(len(results)):</span><br><span class="line">            restored_results.append(results[sorted_key[idx]])</span><br><span class="line"></span><br><span class="line">        <span class="keyword">return</span> bleu(restored_results, references)</span><br><span class="line"></span><br><span class="line">    <span class="keyword">return</span> <span class="number">0.0</span></span><br></pre></td></tr></table></figure>
<p>最后回到<code>evaluate</code>函数：</p>
<figure class="highlight py"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br></pre></td><td class="code"><pre><span class="line"><span class="function"><span class="keyword">def</span> <span class="title">evaluate</span><span class="params">(model, sorted_key, dataset, base_dir, references, params)</span>:</span></span><br><span class="line">    ......</span><br><span class="line">    <span class="comment"># 接下来的工作就是保存和替换checkpoint，暂时没什么用</span></span><br><span class="line">    <span class="comment"># Save records</span></span><br><span class="line">    <span class="keyword">if</span> dist.get_rank() == <span class="number">0</span>:</span><br><span class="line">        scalar(<span class="string">"BLEU/score"</span>, score, global_step, write_every_n_steps=<span class="number">1</span>)</span><br><span class="line">        print(<span class="string">"BLEU at step %d: %f"</span> % (global_step, score))</span><br><span class="line"></span><br><span class="line">        <span class="comment"># Save checkpoint to save_path</span></span><br><span class="line">        save(&#123;<span class="string">"model"</span>: model.state_dict(), <span class="string">"step"</span>: global_step&#125;, save_path)</span><br><span class="line"></span><br><span class="line">        _save_log(log_name, (<span class="string">"BLEU"</span>, global_step, score))</span><br><span class="line">        records = _read_score_record(record_name)</span><br><span class="line">        record = [latest_checkpoint(save_path).split(<span class="string">"/"</span>)[<span class="number">-1</span>], score]</span><br><span class="line"></span><br><span class="line">        added, removed, records = _add_to_record(records, record, max_to_keep)</span><br><span class="line"></span><br><span class="line">        <span class="keyword">if</span> added <span class="keyword">is</span> <span class="keyword">None</span>:</span><br><span class="line">            <span class="comment"># Remove latest checkpoint</span></span><br><span class="line">            filename = latest_checkpoint(save_path)</span><br><span class="line">            print(<span class="string">"Removing %s"</span> % filename)</span><br><span class="line">            files = glob.glob(filename + <span class="string">"*"</span>)</span><br><span class="line"></span><br><span class="line">            <span class="keyword">for</span> name <span class="keyword">in</span> files:</span><br><span class="line">                os.remove(name)</span><br><span class="line"></span><br><span class="line">        <span class="keyword">if</span> removed <span class="keyword">is</span> <span class="keyword">not</span> <span class="keyword">None</span>:</span><br><span class="line">            filename = os.path.join(save_path, removed)</span><br><span class="line">            print(<span class="string">"Removing %s"</span> % filename)</span><br><span class="line">            files = glob.glob(filename + <span class="string">"*"</span>)</span><br><span class="line"></span><br><span class="line">            <span class="keyword">for</span> name <span class="keyword">in</span> files:</span><br><span class="line">                os.remove(name)</span><br><span class="line"></span><br><span class="line">        _save_score_record(record_name, records)</span><br><span class="line"></span><br><span class="line">        best_score = records[<span class="number">0</span>][<span class="number">1</span>]</span><br><span class="line">        print(<span class="string">"Best score at step %d: %f"</span> % (global_step, best_score))</span><br></pre></td></tr></table></figure>
<h2>附录：infer阶段的decoder</h2>

      </div>
        
          <section class='meta' id="footer-meta">
            <hr>
            <div class='new-meta-box'>
              
                <div class="new-meta-item date" itemprop="dateUpdated" datetime="2020-09-07T20:48:59+00:00">
                  <a class='notlink'>
                    <i class="fas fa-save" aria-hidden="true"></i>
                    2020-09-07
                  </a>
                </div>
              
              
                
                <div class="new-meta-item meta-tags"><a class="tag" href="/tags/THUMT/"><i class="fas fa-hashtag" aria-hidden="true"></i>&nbsp;THUMT</a></div>
              
              
            </div>
          </section>
        

        
            <div class="prev-next">
                
                
                    <section class="next">
                        <span class="art-item-right" aria-hidden="true">
                            <h6>下一页&nbsp;<i class="fas fa-chevron-right" aria-hidden="true"></i></h6>
                            <h4>
                                <a href="/post/thumt-code-summary-3/" rel="prev" title="THUMT代码详解（3）：训练阶段模型和数据流">
                                    
                                        THUMT代码详解（3）：训练阶段模型和数据流
                                    
                                </a>
                            </h4>
                            
                                
                                <h6 class="tags">
                                    <a class="tag" href="/tags/THUMT/"><i class="fas fa-hashtag fa-fw" aria-hidden="true"></i>THUMT</a>
                                </h6>
                            
                        </span>
                    </section>
                
            </div>
        

    </section>

</article>

<!-- 根据页面mathjax变量决定是否加载MathJax数学公式js -->


<br>

<!-- 显示推荐文章和评论 -->



  <article class="post white-box comments">
    <section class="article typo">
      <h4><i class="fas fa-comments fa-fw" aria-hidden="true"></i>&nbsp;评论</h4>
      
      
        <section id="comments">
          <div id="lv-container" data-id="city" data-uid="MTAyMC80MjgyNi8xOTM3Mw==">
            <noscript><div><i class='fas fa-exclamation-triangle'>&nbsp;无法加载Livere评论系统，请确保您的网络能够正常访问。</div></noscript>
          </div>
        </section>
      
      
    </section>
  </article>



<script>
    window.subData = {
        title: 'THUMT代码详解（4）：infer阶段模型和数据流',
        tools: true
    }
</script>


        </div>
        <aside class='l_side'>
            
  
  
    
      
      
        <section class='author'>
  <div class='content pure'>
    
    
    
      <div class="social-wrapper">
        
          
            <a href="mailto:zhanghuimeng1997@gmail.com" class="social flat-btn" target="_blank" rel="external"><i class="social fas fa-envelope" aria-hidden="true"></i></a>
          
        
          
            <a href="https://github.com/zhanghuimeng" class="social flat-btn" target="_blank" rel="external"><i class="social fab fa-github" aria-hidden="true"></i></a>
          
        
          
            <a href="https://music.163.com/#/user/home?id=261028414" class="social flat-btn" target="_blank" rel="external"><i class="social fas fa-music" aria-hidden="true"></i></a>
          
        
      </div>
    
  </div>
</section>

      
    
  
    
      
      
        
  <section class='toc-wrapper'>
    
<header class='pure'>
  <div><i class="fas fa-list fa-fw" aria-hidden="true"></i>&nbsp;&nbsp;文章目录</div>
  
    <div class='wrapper'><a class="s-toc rightBtn" rel="external nofollow noopener noreferrer" href="javascript:void(0)"><i class="fas fa-thumbtack fa-fw"></i></a></div>
  
</header>

    <div class='content pure'>
      <ol class="toc"><li class="toc-item toc-level-2"><a class="toc-link" href="#undefined"><span class="toc-text">evaluation</span></a></li><li class="toc-item toc-level-2"><a class="toc-link" href="#undefined"><span class="toc-text">附录：infer阶段的decoder</span></a></li></ol>
    </div>
  </section>


      
    
  
    
      
      
        
  <section class='category'>
    
<header class='pure'>
  <div><i class="fas fa-folder-open fa-fw" aria-hidden="true"></i>&nbsp;&nbsp;所有分类</div>
  
</header>

    <div class='content pure'>
      <ul class="entry">
        
          <li><a class="flat-box" title="/categories/Blogging/" href="/categories/Blogging/"><div class='name'>Blogging</div><div class='badge'>(2)</div></a></li>
        
          <li><a class="flat-box" title="/categories/Codeforces/" href="/categories/Codeforces/"><div class='name'>Codeforces</div><div class='badge'>(4)</div></a></li>
        
          <li><a class="flat-box" title="/categories/Leetcode/" href="/categories/Leetcode/"><div class='name'>Leetcode</div><div class='badge'>(32)</div></a></li>
        
          <li><a class="flat-box" title="/categories/MLDS/" href="/categories/MLDS/"><div class='name'>MLDS</div><div class='badge'>(0)</div></a></li>
        
          <li><a class="flat-box" title="/categories/NLP/" href="/categories/NLP/"><div class='name'>NLP</div><div class='badge'>(5)</div></a></li>
        
          <li><a class="flat-box" title="/categories/USACO/" href="/categories/USACO/"><div class='name'>USACO</div><div class='badge'>(5)</div></a></li>
        
          <li><a class="flat-box" title="/categories/博客/" href="/categories/博客/"><div class='name'>博客</div><div class='badge'>(0)</div></a></li>
        
          <li><a class="flat-box" title="/categories/旧博客/" href="/categories/旧博客/"><div class='name'>旧博客</div><div class='badge'>(2)</div></a></li>
        
          <li><a class="flat-box" title="/categories/机器学习/" href="/categories/机器学习/"><div class='name'>机器学习</div><div class='badge'>(2)</div></a></li>
        
          <li><a class="flat-box" title="/categories/深度学习/" href="/categories/深度学习/"><div class='name'>深度学习</div><div class='badge'>(0)</div></a></li>
        
          <li><a class="flat-box" title="/categories/读书笔记/" href="/categories/读书笔记/"><div class='name'>读书笔记</div><div class='badge'>(16)</div></a></li>
        
          <li><a class="flat-box" title="/categories/随笔/" href="/categories/随笔/"><div class='name'>随笔</div><div class='badge'>(3)</div></a></li>
        
      </ul>
    </div>
  </section>


      
    
  
    
      
      
        
  <section class='tagcloud'>
    
<header class='pure'>
  <div><i class="fas fa-hashtag fa-fw" aria-hidden="true"></i>&nbsp;&nbsp;热门标签</div>
  
</header>

    <div class='content pure'>
      <a href="/tags/A-Munday/" style="font-size: 14px; color: #999">A.Munday</a> <a href="/tags/Blogging/" style="font-size: 14px; color: #999">Blogging</a> <a href="/tags/C-Marlowe/" style="font-size: 14px; color: #999">C.Marlowe</a> <a href="/tags/CSP/" style="font-size: 15.07px; color: #929292">CSP</a> <a href="/tags/Codeforces/" style="font-size: 19.36px; color: #757575">Codeforces</a> <a href="/tags/Codeforces-Contest/" style="font-size: 19px; color: #777">Codeforces Contest</a> <a href="/tags/Counseling/" style="font-size: 14px; color: #999">Counseling</a> <a href="/tags/Cryptography/" style="font-size: 14px; color: #999">Cryptography</a> <a href="/tags/D-Drayton/" style="font-size: 14px; color: #999">D.Drayton</a> <a href="/tags/Deep-Learning/" style="font-size: 15.07px; color: #929292">Deep Learning</a> <a href="/tags/Depth-first-Search/" style="font-size: 14px; color: #999">Depth-first Search</a> <a href="/tags/Deutsch/" style="font-size: 14px; color: #999">Deutsch</a> <a href="/tags/DigitCircuit/" style="font-size: 14px; color: #999">DigitCircuit</a> <a href="/tags/E-Vere/" style="font-size: 14px; color: #999">E. Vere</a> <a href="/tags/E-Spencer/" style="font-size: 14px; color: #999">E.Spencer</a> <a href="/tags/Essay/" style="font-size: 14.36px; color: #979797">Essay</a> <a href="/tags/Flask/" style="font-size: 14px; color: #999">Flask</a> <a href="/tags/Github/" style="font-size: 14.71px; color: #949494">Github</a> <a href="/tags/GoldenTreasury/" style="font-size: 23.29px; color: #5a5a5a">GoldenTreasury</a> <a href="/tags/Google-Analytics/" style="font-size: 14px; color: #999">Google Analytics</a> <a href="/tags/H-Constable/" style="font-size: 14px; color: #999">H.Constable</a> <a href="/tags/Hexo/" style="font-size: 14px; color: #999">Hexo</a> <a href="/tags/J-Donne/" style="font-size: 14px; color: #999">J.Donne</a> <a href="/tags/J-Lyly/" style="font-size: 14px; color: #999">J.Lyly</a> <a href="/tags/J-Sylvester/" style="font-size: 14px; color: #999">J.Sylvester</a> <a href="/tags/J-Webster/" style="font-size: 14px; color: #999">J.Webster</a> <a href="/tags/Leetcode/" style="font-size: 24px; color: #555">Leetcode</a> <a href="/tags/Leetcode-Contest/" style="font-size: 23.64px; color: #575757">Leetcode Contest</a> <a href="/tags/Lyric/" style="font-size: 17.21px; color: #838383">Lyric</a> <a href="/tags/Machine-Learning/" style="font-size: 19.36px; color: #757575">Machine Learning</a> <a href="/tags/Machine-Translation/" style="font-size: 16.5px; color: #888">Machine Translation</a> <a href="/tags/Maths/" style="font-size: 14px; color: #999">Maths</a> <a href="/tags/NLP/" style="font-size: 14px; color: #999">NLP</a> <a href="/tags/Natural-Language-Processing/" style="font-size: 17.21px; color: #838383">Natural Language Processing</a> <a href="/tags/OS/" style="font-size: 21.14px; color: #686868">OS</a> <a href="/tags/OSTEP/" style="font-size: 17.93px; color: #7e7e7e">OSTEP</a> <a href="/tags/Old-Blog/" style="font-size: 14px; color: #999">Old Blog</a> <a href="/tags/OldBlog/" style="font-size: 14.71px; color: #949494">OldBlog</a> <a href="/tags/P-Sidney/" style="font-size: 14px; color: #999">P.Sidney</a> <a href="/tags/PRML/" style="font-size: 18.29px; color: #7c7c7c">PRML</a> <a href="/tags/Paper/" style="font-size: 16.5px; color: #888">Paper</a> <a href="/tags/Paul-Simon/" style="font-size: 14px; color: #999">Paul Simon</a> <a href="/tags/PhysicsExperiment/" style="font-size: 14px; color: #999">PhysicsExperiment</a> <a href="/tags/Psychology/" style="font-size: 14px; color: #999">Psychology</a> <a href="/tags/PyCharm/" style="font-size: 14px; color: #999">PyCharm</a> <a href="/tags/Quality-Estimation/" style="font-size: 15.43px; color: #8f8f8f">Quality Estimation</a> <a href="/tags/R-Barnfield/" style="font-size: 14px; color: #999">R.Barnfield</a> <a href="/tags/Raspberry-Pi/" style="font-size: 14px; color: #999">Raspberry Pi</a> <a href="/tags/Reading-Report/" style="font-size: 17.57px; color: #818181">Reading Report</a> <a href="/tags/S-Daniel/" style="font-size: 14px; color: #999">S.Daniel</a> <a href="/tags/SGU/" style="font-size: 14.36px; color: #979797">SGU</a> <a href="/tags/Sonnet/" style="font-size: 19.71px; color: #727272">Sonnet</a> <a href="/tags/Spokes/" style="font-size: 14.71px; color: #949494">Spokes</a> <a href="/tags/SystemAnalysis-Control/" style="font-size: 14px; color: #999">SystemAnalysis&Control</a> <a href="/tags/T-Dekker/" style="font-size: 14px; color: #999">T.Dekker</a> <a href="/tags/T-Heywood/" style="font-size: 14px; color: #999">T.Heywood</a> <a href="/tags/T-Lodge/" style="font-size: 14px; color: #999">T.Lodge</a> <a href="/tags/T-Nashe/" style="font-size: 14px; color: #999">T.Nashe</a> <a href="/tags/T-Wyatt/" style="font-size: 14px; color: #999">T.Wyatt</a> <a href="/tags/THUMT/" style="font-size: 15.79px; color: #8d8d8d">THUMT</a> <a href="/tags/TensorFlow/" style="font-size: 15.07px; color: #929292">TensorFlow</a> <a href="/tags/Translation/" style="font-size: 18.64px; color: #797979">Translation</a> <a href="/tags/Tree/" style="font-size: 14px; color: #999">Tree</a> <a href="/tags/USACO/" style="font-size: 22.21px; color: #616161">USACO</a> <a href="/tags/W-Alexander/" style="font-size: 14px; color: #999">W.Alexander</a> <a href="/tags/W-Drummond/" style="font-size: 15.07px; color: #929292">W.Drummond</a> <a href="/tags/W-Shakespeare/" style="font-size: 21.5px; color: #666">W.Shakespeare</a> <a href="/tags/WebStorm/" style="font-size: 14px; color: #999">WebStorm</a> <a href="/tags/object-Object/" style="font-size: 14px; color: #999">[object Object]</a> <a href="/tags/alg-Ad-Hoc/" style="font-size: 14.36px; color: #979797">alg:Ad-Hoc</a> <a href="/tags/alg-Aho–Corasick-Algorithm/" style="font-size: 14px; color: #999">alg:Aho–Corasick Algorithm</a> <a href="/tags/alg-Array/" style="font-size: 20.79px; color: #6b6b6b">alg:Array</a> <a href="/tags/alg-Automata/" style="font-size: 14px; color: #999">alg:Automata</a> <a href="/tags/alg-Backtracking/" style="font-size: 15.79px; color: #8d8d8d">alg:Backtracking</a> <a href="/tags/alg-Binary-Indexed-Tree/" style="font-size: 14px; color: #999">alg:Binary Indexed Tree</a> <a href="/tags/alg-Binary-Search/" style="font-size: 16.5px; color: #888">alg:Binary Search</a> <a href="/tags/alg-Binary-Search-Tree/" style="font-size: 16.86px; color: #868686">alg:Binary Search Tree</a> <a href="/tags/alg-Binary-Tree/" style="font-size: 14px; color: #999">alg:Binary Tree</a> <a href="/tags/alg-Binray-Search/" style="font-size: 14px; color: #999">alg:Binray Search</a> <a href="/tags/alg-Bit-Manipulation/" style="font-size: 15.43px; color: #8f8f8f">alg:Bit Manipulation</a> <a href="/tags/alg-Bitmasks/" style="font-size: 14px; color: #999">alg:Bitmasks</a> <a href="/tags/alg-Breadth-First-Search/" style="font-size: 14px; color: #999">alg:Breadth-First Search</a> <a href="/tags/alg-Breadth-first-Search/" style="font-size: 18.29px; color: #7c7c7c">alg:Breadth-first Search</a> <a href="/tags/alg-Breadth-firth-Search/" style="font-size: 14.36px; color: #979797">alg:Breadth-firth Search</a> <a href="/tags/alg-Brute-Force/" style="font-size: 17.21px; color: #838383">alg:Brute Force</a> <a href="/tags/alg-Centroid-Decomposition/" style="font-size: 14px; color: #999">alg:Centroid Decomposition</a> <a href="/tags/alg-Depth-first-Search/" style="font-size: 20.07px; color: #707070">alg:Depth-first Search</a> <a href="/tags/alg-Divide-and-Conquer/" style="font-size: 14px; color: #999">alg:Divide and Conquer</a> <a href="/tags/alg-Dynamic-Porgramming/" style="font-size: 14px; color: #999">alg:Dynamic Porgramming</a> <a href="/tags/alg-Dynamic-Programming/" style="font-size: 22.57px; color: #5f5f5f">alg:Dynamic Programming</a> <a href="/tags/alg-Games/" style="font-size: 14px; color: #999">alg:Games</a> <a href="/tags/alg-Geometry/" style="font-size: 14px; color: #999">alg:Geometry</a> <a href="/tags/alg-Graph/" style="font-size: 15.43px; color: #8f8f8f">alg:Graph</a> <a href="/tags/alg-Greedy/" style="font-size: 21.86px; color: #646464">alg:Greedy</a> <a href="/tags/alg-Hash-Table/" style="font-size: 19.71px; color: #727272">alg:Hash Table</a> <a href="/tags/alg-Heap/" style="font-size: 15.43px; color: #8f8f8f">alg:Heap</a> <a href="/tags/alg-In-Order-Traversal/" style="font-size: 14.36px; color: #979797">alg:In-Order Traversal</a> <a href="/tags/alg-Index-Search-Array/" style="font-size: 14px; color: #999">alg:Index Search Array</a> <a href="/tags/alg-Linked-List/" style="font-size: 15.79px; color: #8d8d8d">alg:Linked List</a> <a href="/tags/alg-Map/" style="font-size: 14px; color: #999">alg:Map</a> <a href="/tags/alg-Math/" style="font-size: 22.93px; color: #5c5c5c">alg:Math</a> <a href="/tags/alg-Matrix/" style="font-size: 14px; color: #999">alg:Matrix</a> <a href="/tags/alg-Meet-in-the-Middle/" style="font-size: 14.36px; color: #979797">alg:Meet in the Middle</a> <a href="/tags/alg-Minimax/" style="font-size: 14.36px; color: #979797">alg:Minimax</a> <a href="/tags/alg-Minmax/" style="font-size: 14px; color: #999">alg:Minmax</a> <a href="/tags/alg-Monotonic-Stack/" style="font-size: 16.14px; color: #8a8a8a">alg:Monotonic Stack</a> <a href="/tags/alg-Network-Flow/" style="font-size: 14px; color: #999">alg:Network Flow</a> <a href="/tags/alg-Priority-Queue/" style="font-size: 14px; color: #999">alg:Priority Queue</a> <a href="/tags/alg-Queue/" style="font-size: 14.71px; color: #949494">alg:Queue</a> <a href="/tags/alg-Rabin-Karp/" style="font-size: 14px; color: #999">alg:Rabin-Karp</a> <a href="/tags/alg-Random/" style="font-size: 14.71px; color: #949494">alg:Random</a> <a href="/tags/alg-Rank-Tree/" style="font-size: 14px; color: #999">alg:Rank Tree</a> <a href="/tags/alg-Recursion/" style="font-size: 15.43px; color: #8f8f8f">alg:Recursion</a> <a href="/tags/alg-Recursive/" style="font-size: 14.36px; color: #979797">alg:Recursive</a> <a href="/tags/alg-Rejection-Sampling/" style="font-size: 14px; color: #999">alg:Rejection Sampling</a> <a href="/tags/alg-Reservoir-Sampling/" style="font-size: 14px; color: #999">alg:Reservoir Sampling</a> <a href="/tags/alg-Segmentation-Tree/" style="font-size: 14px; color: #999">alg:Segmentation Tree</a> <a href="/tags/alg-Set/" style="font-size: 14px; color: #999">alg:Set</a> <a href="/tags/alg-Sliding-Window/" style="font-size: 14px; color: #999">alg:Sliding Window</a> <a href="/tags/alg-Sort/" style="font-size: 15.07px; color: #929292">alg:Sort</a> <a href="/tags/alg-Stack/" style="font-size: 19px; color: #777">alg:Stack</a> <a href="/tags/alg-String/" style="font-size: 19px; color: #777">alg:String</a> <a href="/tags/alg-Suffix-Array/" style="font-size: 14px; color: #999">alg:Suffix Array</a> <a href="/tags/alg-Suffix-Tree/" style="font-size: 14px; color: #999">alg:Suffix Tree</a> <a href="/tags/alg-Ternary-Search/" style="font-size: 14px; color: #999">alg:Ternary Search</a> <a href="/tags/alg-Topological-Sort/" style="font-size: 14px; color: #999">alg:Topological Sort</a> <a href="/tags/alg-Treap/" style="font-size: 14px; color: #999">alg:Treap</a> <a href="/tags/alg-Tree/" style="font-size: 20.43px; color: #6d6d6d">alg:Tree</a> <a href="/tags/alg-Trie/" style="font-size: 14.36px; color: #979797">alg:Trie</a> <a href="/tags/alg-Two-Pointers/" style="font-size: 17.93px; color: #7e7e7e">alg:Two Pointers</a> <a href="/tags/alg-Union-find-Forest/" style="font-size: 15.43px; color: #8f8f8f">alg:Union-find Forest</a> <a href="/tags/artist-Ceremony/" style="font-size: 14px; color: #999">artist:Ceremony</a> <a href="/tags/artist-Cruel-Hand/" style="font-size: 14.36px; color: #979797">artist:Cruel Hand</a> <a href="/tags/artist-Have-Heart/" style="font-size: 14px; color: #999">artist:Have Heart</a> <a href="/tags/artist-Johnny-Cash/" style="font-size: 14px; color: #999">artist:Johnny Cash</a> <a href="/tags/artist-Touche-Amore/" style="font-size: 14px; color: #999">artist:Touche Amore</a> <a href="/tags/artist-Wir-Sind-Helden/" style="font-size: 14.71px; color: #949494">artist:Wir Sind Helden</a> <a href="/tags/translation/" style="font-size: 14.36px; color: #979797">translation</a> <a href="/tags/ucore/" style="font-size: 14px; color: #999">ucore</a> <a href="/tags/付勇林/" style="font-size: 15.79px; color: #8d8d8d">付勇林</a> <a href="/tags/卞之琳/" style="font-size: 14px; color: #999">卞之琳</a> <a href="/tags/屠岸/" style="font-size: 16.14px; color: #8a8a8a">屠岸</a> <a href="/tags/戴镏龄/" style="font-size: 15.79px; color: #8d8d8d">戴镏龄</a> <a href="/tags/曹明伦/" style="font-size: 15.43px; color: #8f8f8f">曹明伦</a> <a href="/tags/朱生豪/" style="font-size: 17.57px; color: #818181">朱生豪</a> <a href="/tags/李霁野/" style="font-size: 15.07px; color: #929292">李霁野</a> <a href="/tags/杨熙龄/" style="font-size: 14px; color: #999">杨熙龄</a> <a href="/tags/林天斗/" style="font-size: 14px; color: #999">林天斗</a> <a href="/tags/梁宗岱/" style="font-size: 16.86px; color: #868686">梁宗岱</a> <a href="/tags/梁葆成/" style="font-size: 14px; color: #999">梁葆成</a> <a href="/tags/袁广达/" style="font-size: 14px; color: #999">袁广达</a> <a href="/tags/郭沫若/" style="font-size: 14px; color: #999">郭沫若</a> <a href="/tags/黄新渠/" style="font-size: 14px; color: #999">黄新渠</a>
    </div>
  </section>


      
    
  
    
      
      
        <section class='list'>
  
<header class='pure'>
  <div><i class="fas fa-link fa-fw" aria-hidden="true"></i>&nbsp;&nbsp;特别链接</div>
  
</header>

  <div class='content pure'>
    <ul class="entry">
      
        <li><a class="flat-box" title="https://wenj.github.io/" href="https://wenj.github.io/">
          <div class='name'>
            
              <i class="fas fa-comment-dots fa-fw" aria-hidden="true"></i>
            
            &nbsp;&nbsp;wenj
          </div>
          
        </a></li>
      
        <li><a class="flat-box" title="http://bellasong.site/" href="http://bellasong.site/">
          <div class='name'>
            
              <i class="fas fa-comment-dots fa-fw" aria-hidden="true"></i>
            
            &nbsp;&nbsp;ssh
          </div>
          
        </a></li>
      
    </ul>
  </div>
</section>

      
    
  


        </aside>
        <script>setLoadingBarProgress(60);</script>
    </div>
    <a class="s-top fas fa-arrow-up fa-fw" href='javascript:void(0)'></a>
    </div>
    <footer id="footer" class="clearfix">
  
  
    <div class="social-wrapper">
      
        
          <a href="mailto:zhanghuimeng1997@gmail.com" class="social fas fa-envelope flat-btn" target="_blank" rel="external"></a>
        
      
        
          <a href="https://github.com/zhanghuimeng" class="social fab fa-github flat-btn" target="_blank" rel="external"></a>
        
      
        
          <a href="https://music.163.com/#/user/home?id=261028414" class="social fas fa-music flat-btn" target="_blank" rel="external"></a>
        
      
    </div>
  
  <br>
  <div><p>博客内容遵循 <a href="https://creativecommons.org/licenses/by-nc-sa/4.0/deed.zh">署名-非商业性使用-相同方式共享 4.0 国际 (CC BY-NC-SA 4.0) 协议</a></p>
</div>
  <div>本站使用 <a href="https://xaoxuu.com/wiki/material-x/" target="_blank" class="codename">Material X</a> 作为主题，总访问量为 <span id="busuanzi_value_site_pv"><i class="fas fa-spinner fa-spin fa-fw" aria-hidden="true"></i></span> 次。
  </div>
</footer>

    <script>setLoadingBarProgress(80);</script>
    <script src="https://cdn.jsdelivr.net/npm/jquery@3.2.1/dist/jquery.min.js"></script>

  <script>
    var GOOGLE_CUSTOM_SEARCH_API_KEY = "";
    var GOOGLE_CUSTOM_SEARCH_ENGINE_ID = "";
    var ALGOLIA_API_KEY = "";
    var ALGOLIA_APP_ID = "";
    var ALGOLIA_INDEX_NAME = "";
    var AZURE_SERVICE_NAME = "";
    var AZURE_INDEX_NAME = "";
    var AZURE_QUERY_KEY = "";
    var BAIDU_API_ID = "";
    var SEARCH_SERVICE = "hexo" || "hexo";
    var ROOT = "/"||"/";
    if(!ROOT.endsWith('/'))ROOT += '/';
  </script>



  <script async src="https://cdn.jsdelivr.net/npm/scrollreveal@4.0.5/dist/scrollreveal.min.js"></script>
  <script type="text/javascript">
    $(function() {
      const $reveal = $('.reveal');
      if ($reveal.length === 0) return;
      const sr = ScrollReveal({ distance: 0 });
      sr.reveal('.reveal');
    });
  </script>


  <script src="https://cdn.jsdelivr.net/npm/node-waves@0.7.6/dist/waves.min.js"></script>
  <script type="text/javascript">
    $(function() {
      Waves.attach('.flat-btn', ['waves-button']);
      Waves.attach('.float-btn', ['waves-button', 'waves-float']);
      Waves.attach('.float-btn-light', ['waves-button', 'waves-float', 'waves-light']);
      Waves.attach('.flat-box', ['waves-block']);
      Waves.attach('.float-box', ['waves-block', 'waves-float']);
      Waves.attach('.waves-image');
      Waves.init();
    });
  </script>


  <script async src="https://cdn.jsdelivr.net/gh/xaoxuu/cdn-busuanzi@2.3/js/busuanzi.pure.mini.js"></script>







  <script type="text/javascript">
    (function(d, s) {
      var j, e = d.getElementsByTagName(s)[0];
      if (typeof LivereTower === 'function') { return; }
      j = d.createElement(s);
      j.src = 'https://cdn-city.livere.com/js/embed.dist.js';
      j.async = true;
      e.parentNode.insertBefore(j, e);
    })(document, 'script');
  </script>





  <script src="/js/app.js"></script>
<script src="/js/search.js"></script>





<!-- 复制 -->
<script src="https://cdn.jsdelivr.net/npm/clipboard@2/dist/clipboard.min.js"></script>
<script>
  let COPY_SUCCESS = "复制成功";
  let COPY_FAILURE = "复制失败";
  /*页面载入完成后，创建复制按钮*/
  !function (e, t, a) {
    /* code */
    var initCopyCode = function(){
      var copyHtml = '';
      copyHtml += '<button class="btn-copy" data-clipboard-snippet="">';
      copyHtml += '  <i class="fa fa-copy"></i><span>Copy</span>';
      copyHtml += '</button>';
      $(".highlight .code pre").before(copyHtml);
      var clipboard = new ClipboardJS('.btn-copy', {
        target: function(trigger) {
          return trigger.nextElementSibling;
        }
      });

      clipboard.on('success', function(e) {
        //您可以加入成功提示
        console.info('Action:', e.action);
        console.info('Text:', e.text);
        console.info('Trigger:', e.trigger);
        success_prompt(COPY_SUCCESS);
        e.clearSelection();
      });
      clipboard.on('error', function(e) {
        //您可以加入失败提示
        console.error('Action:', e.action);
        console.error('Trigger:', e.trigger);
        fail_prompt(COPY_FAILURE);
      });
    }
    initCopyCode();

  }(window, document);

  /**
   * 弹出式提示框，默认1.5秒自动消失
   * @param message 提示信息
   * @param style 提示样式，有alert-success、alert-danger、alert-warning、alert-info
   * @param time 消失时间
   */
  var prompt = function (message, style, time)
  {
      style = (style === undefined) ? 'alert-success' : style;
      time = (time === undefined) ? 1500 : time*1000;
      $('<div>')
          .appendTo('body')
          .addClass('alert ' + style)
          .html(message)
          .show()
          .delay(time)
          .fadeOut();
  };

  // 成功提示
  var success_prompt = function(message, time)
  {
      prompt(message, 'alert-success', time);
  };

  // 失败提示
  var fail_prompt = function(message, time)
  {
      prompt(message, 'alert-danger', time);
  };

  // 提醒
  var warning_prompt = function(message, time)
  {
      prompt(message, 'alert-warning', time);
  };

  // 信息提示
  var info_prompt = function(message, time)
  {
      prompt(message, 'alert-info', time);
  };

</script>


<!-- fancybox -->
<script src="https://cdn.jsdelivr.net/gh/fancyapps/fancybox@3.5.7/dist/jquery.fancybox.min.js"></script>
<script>
  let LAZY_LOAD_IMAGE = "";
  $(".article-entry").find("img").each(function () {
      var element = document.createElement("a");
      $(element).attr("data-fancybox", "gallery");
      $(element).attr("href", $(this).attr("src"));
      /* 图片采用懒加载处理时,
       * 一般图片标签内会有个属性名来存放图片的真实地址，比如 data-original,
       * 那么此处将原本的属性名src替换为对应属性名data-original,
       * 修改如下
       */
       if (LAZY_LOAD_IMAGE) {
         $(element).attr("href", $(this).attr("data-original"));
       }
      $(this).wrap(element);
  });
</script>





    <script>setLoadingBarProgress(100);</script><!-- hexo-inject:begin --><!-- hexo-inject:end -->
</body>
</html>
