---
title: 机器学习速成课程（1）：构建一个简单的线性模型
urlname: machine-learning-crash-course-1-construct-a-simple-linear-model
toc: true
mathjax: true
date: 2018-09-21 19:19:02
updated: 2018-09-22 17:01:00
tags: [Machine Learning, TensorFlow]
---

课：[机器学习速成课程](https://developers.google.com/machine-learning/crash-course/?hl=zh-cn)

## 课程内容

### 基本概念

首先介绍了监督式机器学习的概念并给出了一些定义。

**标签**：我们要预测的事物（简单线性回归中的y变量）

**特征**：表示数据的方式，用于描述数据的输入变量。

**样本**：数据的特定实例，分为有标签和无标签两类。

创建模型即从数据中学习规律的过程。

模型生命周期的两个阶段：

* 训练：创建模型，让模型逐渐学习特征与标签之间的关系
* 推断：将训练后的模型应用于无标签样本

模型的一种分类方法：

* 回归模型：预测连续值
* 分类模型：预测离散值

然后介绍了关于线性回归模型（和通用模型）的一些基本概念。线性回归模型用一条直线对样本的标签进行推断，即

$$y = wx + b$$

**损失**：对单个样本而言模型预测的准确程度。

给定样本的$L_2$损失（平方误差）：$(\text{观察值} - \text{预测值})^2$

数据集上的$L_2$损失：$L_2 loss = \sum_{(x, y) \in D} (y - prediction(x))^2$

**均方误差**（MSE，Mean Squared Error）：每个样本的平均平方损失

在监督式学习中，机器学习算法通过以下方式构建模型：检查多个样本并尝试找出可最大限度地减少损失的模型；这一过程称为经验风险最小化。

### 减少损失

下一个问题就是如何选择合适的模型参数以减小误差。

常用的方法是，通过计算梯度获得与模型参数相关的误差函数的导数，并沿着梯度指出的方向前进。这可以视为一种迭代法。

迭代法有几个需要考虑的问题。一个问题是沿着这一方向需要前进多少，这被称为学习速率（learning rate）。这是一个超参数。我们需要找到一个合适的学习速率，使得梯度下降过程高效收敛，但又不会高到使该过程永远无法收敛。

另一个问题是起始的位置。对于凸形问题，任意起始位置都是可取的；但很多问题（如神经网络）并不是凸形问题。它们有很多可能的极小值，其中一些比其他更优。

最后一个问题是如何计算梯度。为了得到正确的梯度方向，需要对数据集中所有样本的梯度进行计算。但是一般来说样本量太大，这样计算复杂度太高。所以可以转而计算小型样本的梯度，有两种方法：

* 随机梯度下降法（SGD，Stochastic Gradient Descent）：每次只抽取一个样本计算梯度。这一方法最终会收敛，但可能速度太慢，且过程比较杂乱
* 小批量梯度下降法（small batch SGD）：每批包含10-1000个样本，可以减少杂乱的过程

训练模型是一个迭代的过程：将特征输入当前的模型，返回一个预测作为输出，计算输出的损失，生成新的参数值。当总体损失不再变化或变化极其缓慢时，我们称模型收敛。

梯度是偏导数的矢量，具有两个特征：方向和大小。梯度指向函数增长速度最快的方向，负梯度指向函数下降速度最快的方向。

梯度下降法用梯度乘以一个称为学习速率（步长）的标量，以确定下一个点的位置。如果学习速率过小，则会花费过长的学习时间；否则可能无法收敛。合适的学习速率取决于损失函数的平坦程度。

理想的学习速率：

* 一维空间：理想学习速率是$1 / f(x)''$
* 二维或多维空间：理想学习速率是1 / Hessian矩阵
* 广义凸函数：很难确定


## 编码练习：使用LinearRegressor构建模型

我参照[first_steps_with_tensor_flow.ipynb](https://colab.research.google.com/notebooks/mlcc/first_steps_with_tensor_flow.ipynb?utm_source=mlcc&utm_campaign=colab-external&utm_medium=referral&utm_content=firststeps-colab&hl=zh-cn#scrollTo=Bd2Zkk1LE2Zr)中的内容在本地写了一遍并运行了一下。

我大概从这一过程中学到了：

* PyCharm的安装和使用，以及venv虚拟环境的使用
* 用Estimator API构建和训练模型的基本步骤：
  * 定义`optimizer`和`feature_columns`
  * 定义数据输入函数
  * 用数据输入函数对模型进行若干步训练
  * 用预测数据输入函数对模型进行测试
* `pandas.Dataframe`的基本使用方法和它与`numpy`如何联合使用
* 用`describe`、直方图等方法观察数据的分布，寻找离群值
* 用`matplotlib.pyplot`对数据特征和训练过程中的RMSE变化进行可视化表示

下一个问题是如何调整超参数。简单来说，不同超参数的效果取决于数据。因此没有必须遵循的规则，需要对自己的数据进行测试。不过，仍然有一些经验法则：

* 训练误差应该稳步减小；开始时急剧减小，最终应随着训练收敛达到平稳状态。
* 如果训练没有收敛，尝试运行更长的时间。
* 如果训练误差减小速度过慢，则提高学习速率可能有助于加快其减小速度。
  * 但有时如果学习速率过高，训练误差的减小速度反而会变慢。
  * 如果训练误差变化很大，尝试降低学习速率。
  * 较低的学习速率和较大的步数/较大的批量大小通常是不错的组合
* 批量大小过小也会导致不稳定情况。不妨先尝试100或1000等较大的值，然后逐渐减小值的大小，直到出现性能降低的情况。

以及在代码中：

* steps：指训练迭代的总次数。一步计算一批样本产生的损失，然后使用该值修改模型的权重一次。
* batch size：是指单步的样本数量（随机选择）。例如，SGD的批量大小为1。

总被训练样本数 = batch size * steps

* periods：控制报告的粒度。例如，如果periods设为7且steps设为70，则练习将每10步（共输出7次）输出一次损失值。

每period被训练的样本数 = batch size * steps / periods

我随便调了几组参数。我觉得目前这不是重点，所以就不写了。

完整代码见[learnTensorFlow/first_linear_regression/first_steps.py](https://github.com/zhanghuimeng/learnTensorFlow/blob/master/first_linear_regression/first_steps.py)。

<script src="http://gist-it.appspot.com/https://github.com/zhanghuimeng/learnTensorFlow/blob/master/first_linear_regression/first_steps.py"></script>
