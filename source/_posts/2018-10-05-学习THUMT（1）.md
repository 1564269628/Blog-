---
title: 学习THUMT（1）：UserManual和代码结构
urlname: learn-thumt-1
toc: true
date: 2018-10-05 14:55:37
updated: 2018-10-05 14:55:37
tags: [Natural Language Processing, Machine Learning, THUMT]
---

代码：[THUMT](https://github.com/thumt/THUMT)

## 目录结构

目前`thumt/`文件夹下的目录结构是这样的：

* `bin/`
  * `get_relevance.py`：输入训练好的模型checkpoints、模型在测试数据上的输入和输出、词表，输出测试数据中每个句子及其翻译之间的关联矩阵。（似乎只对Transformer和RNNsearch模型有效）。
  * `scorer.py`：暂时不知道是做什么的。
  * `trainer.py`：用于训练模型，输入训练数据、词表、验证数据、参数，输出训练模型的checkpoints和在验证集上的得分。
  * `translator.py`：用训练好的模型对测试数据进行翻译，输入模型checkpoints、测试数据、词表，输出翻译结果。
* `data/`
  * `__init__.py`：这是一个模块。
  * `cache.py`：从字义上看好像是存储feature用的，实际上看不懂。
  * `dataset.py`：输入训练和验证数据文件，将数据分成batch。
  * `record.py`：看起来和`dataset.py`有点像，仍然不知道是干什么的。
  * `vocab.py`：加载和处理词表。
* `interface/`
  * `__init__.py`：这是一个模块。
  * `model.py`：表示NMT模型的抽象类`NMTModel`。
* `layers/`
  * `__init__.py`：这是一个模块。
  * `attention.py`：Attention机制的实现。
  * `nn.py`：一些神经网络层的实现，包括`linear`和`maxout`。
  * `rnn_cell.py`：GRU的实现，以及一些wrapper。
* `models/`
  * `__init__.py`：这是一个模块。
  * `rnnsearch.py`：RNNsearch模型的实现。
  * `rnnsearch_lrp.py`：[LRP](http://www.aclweb.org/anthology/P17-1106)和RNNsearch模型的实现。
  * `seq2seq.py`：Seq2Seq模型的实现。
  * `transformer.py`：Transformer模型的实现。
  * `transformer_lrq.py`：LRP和Transformer模型的实现。
* `scripts/`
  * `build_vocab.py`：通过输入的测试数据创建词表。
  * `checkpoint_averaging.py`：输入模型checkpoints，输出平均结果。
  * `convert_old_model.py`：看起来好像是用于把旧实现生成的模型转换成新模型的。
  * `convert_vocab.py`：不知道是干什么的。
  * `input_converter.py`：把输入转换成`tf.Record`格式。不知道有什么用。
  * `shuffle_corpus.py`：随机打乱训练数据。
  * `visualize.py`：对Transformer或RNNsearch输出的关联矩阵进行可视化。
* `utils/`
  * `__init__.py`：这是一个模块。
  * `bleu.py`：BLEU值的计算。
  * `common.py`：看起来好像是一些用于推导形状的函数。
  * `hooks.py`：用于保存模型checkpoint。
  * `inference.py`：实现了Beam Search和不知道是什么的Inference。
  * `lrp_utils.py`：看名字可能和LRP有关，实际上好像有很多模型的实现，并不知道是干什么的。
  * `optimize.py`：不知道是干什么的。
  * `parallel.py`：看起来好像是用于多GPU训练的。
  * `sampling.py`：？
  * `weight_ratio.py`：？
* `__init__.py`：这是一个模块。

## 训练过程

一般来说训练过程可以分成以下几个阶段：

* 准备数据
  * 训练集、验证集、测试集语料
  * 用训练集生成BPE操作和词典（大概？）
  * 用上述BPE操作和词典对训练集、验证集和测试集的源语言部分分别进行处理
  * 将训练集随机排序（`shuffle_corpus.py`）
  * 通过训练集生成词表（`build_vocab.py`）
* 训练：输入训练集、验证集和词表，输出模型checkpoints、在验证集上得分最高的模型，以及模型在训练过程中在验证集上的评测结果
* 测试：
  * 输入测试集、词表和模型checkpoints，输出翻译结果（`translator.py`），经过一定处理后可以得到BLEU分值
  * 可以进行model averaging（`checkpoint_averaging.py`）
  * 可以进行model ensemble（`translator.py`）
* 可视化：输入测试集、词表、模型checkpoints，输出模型在每个翻译句对上的关联矩阵（`get_relevance.py`，`visualize.py`）

---

明天我打算用比较少的数据在自己的电脑上试验一下。
